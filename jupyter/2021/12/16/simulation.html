<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Ising model dynamics | statistical mechanics and spin glasses</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Ising model dynamics" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="…" />
<meta property="og:description" content="…" />
<link rel="canonical" href="https://the-ninth-wave.github.io/stat-mech/jupyter/2021/12/16/simulation.html" />
<meta property="og:url" content="https://the-ninth-wave.github.io/stat-mech/jupyter/2021/12/16/simulation.html" />
<meta property="og:site_name" content="statistical mechanics and spin glasses" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-16T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"…","url":"https://the-ninth-wave.github.io/stat-mech/jupyter/2021/12/16/simulation.html","@type":"BlogPosting","headline":"Ising model dynamics","dateModified":"2021-12-16T00:00:00-06:00","datePublished":"2021-12-16T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://the-ninth-wave.github.io/stat-mech/jupyter/2021/12/16/simulation.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/stat-mech/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://the-ninth-wave.github.io/stat-mech/feed.xml" title="statistical mechanics and spin glasses" /><link rel="shortcut icon" type="image/x-icon" href="/stat-mech/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/stat-mech/">statistical mechanics and spin glasses</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/stat-mech/about/">About Me</a><a class="page-link" href="/stat-mech/search/">Search</a><a class="page-link" href="/stat-mech/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Ising model dynamics</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-16T00:00:00-06:00" itemprop="datePublished">
        Dec 16, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      70 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/stat-mech/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/the-ninth-wave/stat-mech/tree/master/_notebooks/2021-12-16-simulation.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/stat-mech/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/the-ninth-wave/stat-mech/master?filepath=_notebooks%2F2021-12-16-simulation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/stat-mech/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/the-ninth-wave/stat-mech/blob/master/_notebooks/2021-12-16-simulation.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/stat-mech/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Markov-chains,-Monte-Carlo-methods,-pattern-theory">Markov chains, Monte Carlo methods, pattern theory </a>
<ul>
<li class="toc-entry toc-h2"><a href="#direct-sampling">direct sampling </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Unif">Unif </a></li>
<li class="toc-entry toc-h3"><a href="#Algorithm.-(-direct_pi-)">Algorithm. ( direct_pi ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Markov-chain-sampling">Markov-chain sampling </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Algorithm.-(-markov-pi,-unmodified-)">Algorithm. ( markov-pi, unmodified ) </a></li>
<li class="toc-entry toc-h3"><a href="#Algorithm.--(-markov-pi,-modified-)">Algorithm.  ( markov-pi, modified ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#discussion">discussion </a></li>
<li class="toc-entry toc-h2"><a href="#Markov-chains">Markov chains </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Definition.-(-stochastic-process-)">Definition. ( stochastic process ) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-Markov-chain-)">Definition. ( Markov chain ) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-stationary-Markov-chain-)">Definition. ( stationary Markov chain ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#equilibrium-measures,-ergodicity,-random-walks">equilibrium measures, ergodicity, random walks </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Definition.-(-equilibrium-/-stationary-distribution-)">Definition. ( equilibrium / stationary distribution ) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-ergodic-Markov-chain-)">Definition. ( ergodic Markov chain ) </a></li>
<li class="toc-entry toc-h3"><a href="#Example.-(-simple-random-walk-)">Example. ( simple random walk ) </a></li>
<li class="toc-entry toc-h3"><a href="#Example.-(-random-walks-in-the-permutation-group-)">Example. ( random walks in the permutation group ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Shannon's-model-of-text">Shannon&#39;s model of text </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Definition.-(-stationary-stochastic-process-)">Definition. ( stationary stochastic process ) </a></li>
<li class="toc-entry toc-h3"><a href="#Example.-(-digram-model-)">Example. ( digram model ) </a></li>
<li class="toc-entry toc-h3"><a href="#Example.-(-trigram-model-)">Example. ( trigram model ) </a></li>
<li class="toc-entry toc-h3"><a href="#Example.-(-$(n+1$)-gram-model-)">Example. ( $(n+1$)-gram model ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#information-theory">information theory </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Definition.-(-lossless-data-compression-)">Definition. ( lossless data compression ) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-entropy-)">Definition. ( entropy ) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-$\epsilon$-typical-signal-)">Definition. ( $\epsilon$-typical signal ) </a></li>
<li class="toc-entry toc-h3"><a href="#Theorem.-(-Matic,-Theorem-1)">Theorem. ( Matic, Theorem 1) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-the-type-of-a-signal-)">Definition. ( the type of a signal ) </a></li>
<li class="toc-entry toc-h3"><a href="#Theorem.-(-Matic,-Theorem-2-)">Theorem. ( Matic, Theorem 2 ) </a></li>
<li class="toc-entry toc-h3"><a href="#Definition.-(-relative-entropy,-or-KL-divergence-)">Definition. ( relative entropy, or KL divergence ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Gibbs-measures">Gibbs measures </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Definition.-(-Gibbs-measure-)">Definition. ( Gibbs measure ) </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#simulation">simulation </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Ising-model">Ising model </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Definition.-(-Ising-Hamiltonian-)">Definition. ( Ising Hamiltonian ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#dynamics">dynamics </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Algorithm.-(-Metropolis-Hastings-)">Algorithm. ( Metropolis-Hastings ) </a></li>
<li class="toc-entry toc-h3"><a href="#Algorithm.-(-Glauber-)">Algorithm. ( Glauber ) </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#implementation">implementation </a>
<ul>
<li class="toc-entry toc-h3"><a href="#coin_toss">coin_toss </a></li>
<li class="toc-entry toc-h3"><a href="#grid">grid </a></li>
</ul>
</li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-16-simulation.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><em>project outline</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ These notes supplement an ongoing project with a good friend, <a href="https://github.com/connorsempek">Connor Sempek</a>. Our main objective is to re-create simulations of Ising model dynamics from <a href="http://bit-player.org/2021/three-months-in-monte-carlo">this</a> blog post by <a href="http://bit-player.org/about-the-author">Brian Hayes</a>. The underlying 'canvas' of the model is two-dimensional, and the simulation generates a sequence of two-color <code>100x100</code> pixel images. The two colors represent the two possible <em>spin</em> values of the <a href="https://www.unige.ch/math/folks/velenik/smbook/Ising_Model.pdf">Ising model</a>, $+1$ and $-1$ (though the term spin is used, the model is not quantum-mechanical). The magnetic interpretation is of the model is that each pixel is some atomic site in a crystal lattice, and the color value of each pixel describes one of two opposing magnetic orientations the atom can posess. At a given temperature $T$, a sample from the Ising model (in our context) corresponds to a randomly generated image. The dynamics of the Ising model correspond to a movie formed by a sequence of these images. Each image is obtained from the previous in the sequence by randomly updating the spin $\equiv$ color at a randomly selected pixel, updating one pixel at a time. This movie is analogous to viewing a bar of iron under a microscope, in slow motion.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Parameter $T &gt; 0$ controls the degree of structure in the random images generated. At high enough temperatures, any impulse neighboring spins feel to align is nearly washed away by thermal noise. In this regime, the simulation should look very much like static. At low temperatures, the spins exhibit collective alignment, and the simulation should depict large patches of sites all with the same color. The qualitative behavior of the system changes as it crosses a specific <em>critical temperature</em> $T_c$. For the same phenomenon in iron, this $T_c$ is called the Curie temperature, and corresponds to the bar glowing a dull red. A bar of magnetized iron will lose its magnetization when heated above $T_c$. When its temperature is lowered back below $T_c$, the bar is again susceptible to magnetization: immersing the bar in a strong enough magnetic field causes its spins to align with the field.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The above description of the phase transition occuring in iron requires that we observe the behavior of the iron bar as its temperature changes over time. This is natural in reality, where time appears to flow at a constant rate. However, as discussed, a sample from the Ising model at some temperature $T$ is a static picture. In order to simulate in the Ising model what we describe doing to the iron bar, one must first describe how to set the Ising model into motion. There will be two ways of doing this at a fixed temperature $T$, described by two distinct Markovian dynamics defined on the state space of the Ising model. These are so-called <em>Glauber</em> and <em>Metropolis</em> dynamics. One goal of the <a href="http://bit-player.org/2021/three-months-in-monte-carlo">motivating blog post</a> was to explore how these dynamics differ, and indeed they are visibly different in the simulation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Hayes' simulation is quite versitile: in real-time, one can adjust the temperature, as well as the 'mode' of the dynamics (Glauber or Metropolis). There is no external magnetic field present, but this is something one could easily insert, so his simulation is robust enough to reproduce the procedure with the iron bar. The first incarnation of our simulation will not be, but this is partly because there are some important questions to address even before scheduling a gradual change in temperature during the simulation, or making it more interactive.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ It is written in Python, later to be migrated to javascript. We can currently simulates either type of Ising dynamics for a fixed number of steps, and at a fixed temperature. We do not yet include an external magnetic field. In either type of dynamics, the system (or image) is updated one pixel at a time, and we will perform a large number of updates, let us call this $N$. The output of the simulation is stored in dict format as a <code>.json</code> file. The purpose of the notes below (leading up to the simulation) is to develop some of the theory underlying the Monte Carlo method. Then we will be equipped to address the aforementioned questions, which are: how long the simulation must be run so that, for a sparse enough subsequence of the images:</p>
<ul>
<li>
<p>Each is sampled approximately from the <a href="https://en.wikipedia.org/wiki/Gibbs_measure">Gibbs probability measure</a> governing the Ising model, and</p>
</li>
<li>
<p>these samples are nearly independent?</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The latter property is especially important for a longer term goal of the project, which is to use these subsequences of images as the dataset for a computer vision project. Importantly, the Gibbs measure we are sampling from always depends on a global temperature parameter $T$, leading to natural classification and regression tasks.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><em>to explore</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Here is a starting point for formulating a classification task. Suppose that we can simulate Ising model dynamics well $-$ so that both bullet points above are satisfied $-$ at two <em>distinct</em> temperatures. It feels natural to choose one of these, say $T_1$, above the critical temperature $T_c$ of the model, and the other, $T_2$ below it. We then create two image datasets $\mathcal{D}_1$ and $\mathcal{D}_2$ of equal size by simulating as described by the two points above. Merging these datasets to form what we call $\mathcal{D}$ leads to a natural classification problem: given an element $x \in \mathcal{D}$ chosen uniformly at random, determine whether it came from $\mathcal{D}_1$ or $\mathcal{D}_2$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ It seems the relevance of the Ising model to vision has been explored in depth. A lot of the text below draws from Govind Menon's <a href="https://www.dam.brown.edu/people/menon/publications/pt-2020.pdf">pattern theory</a> notes, where a chapter is devoted to this: specifically an 'energetic' perspective applied to character recognition tasks. Menon's notes also reference a 1984 <a href="http://www.peterbeerli.com/classes/images/a/a1/Geman_geman_1984.pdf">paper</a> which develops a way to perform image restoration and enhancement using the Ising model. This makes it a natural model to experiment with, and there are a few natural ML directions to play with longer term:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>At the lower temperature, $T_2$, simulating the model is akin to an optimization problem: as $T \to 0$, the Gibbs measure concentrates on the set of lowest-energy states, or <em>ground states</em>. Any simulation designed to sample from a low-temperature Gibbs measure needs to navigate the energy landscape of the system from some starting point to a low altitude, with the temperature dictating a small range of desirable low altitudes $\equiv$ low energies. This is effectively an optimization problem with cost function corresponding to the energy landscape. There is also an optimization inherent to the process of training any neural network on the classification task suggested. The question to explore, loosely, is whether there are useful connections between these optimization problems. </li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>We will train a simple convolutional architecture on the dataset $\mathcal{D}$. Whether it is through pooling layers, or the local averaging inherent in the convolution operation, these architectures seem to apply a kind of <a href="https://en.wikipedia.org/wiki/Coarse-grained_modeling">coarse-graining</a> to input signals $x \in \mathcal{D}$. This has prompted investigation into the connections between deep learning and the <a href="https://en.wikipedia.org/wiki/Renormalization_group">renormalization group</a> of physics. The latter feels like a kind of microscope for theoretical physicists: the renormalization group formalizes a sequence of scaling transformations acting on a physical system, typically zooming out and thereby coarse-graining (lowering the resolution of) the preceding image of the system. This parallels the transformations undergone by an image fed into a "deep" sequence of convolutional layers, as this input signal propagates from one layer to the next. Two references exploring connections between renormalization and ML are a 2013 <a href="https://arxiv.org/abs/1301.3124">paper</a> of Cédric Bény, and a 2014 <a href="https://arxiv.org/abs/1410.3831v1">paper</a> of Pankaj Mehta and David Schwab. We imagine there is also more recent work on this to explore. Dataset $\mathcal{D}$ is both an image dataset and a natural input to the renormalization group. It's an opportunity to better understand these connections. In particular one can start by repeating the experiments the latter paper runs on the Ising model.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Markov-chains,-Monte-Carlo-methods,-pattern-theory">
<a class="anchor" href="#Markov-chains,-Monte-Carlo-methods,-pattern-theory" aria-hidden="true"><span class="octicon octicon-link"></span></a>Markov chains, Monte Carlo methods, pattern theory<a class="anchor-link" href="#Markov-chains,-Monte-Carlo-methods,-pattern-theory"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><em>references</em></p>
<ul>
<li>
<p><a href="http://www.lps.ens.fr/~krauth/index.php/Main_Page">Werner Krauth</a> ... Statistical Mechanics: Algorithms and Computations</p>
</li>
<li>
<p><a href="https://www.dam.brown.edu/people/menon/">Govind Menon</a> ...  <a href="https://www.dam.brown.edu/people/menon/new_pub.html">Pattern Theory</a></p>
</li>
</ul>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The Monte Carlo method is increasingly becoming part of the discipline it is meant to study. The Monte Carlo method is a statistical (Krauth: <em>"almost experimental"</em>) approach to computing integrals using random positions, called <strong>samples</strong>. Some sampling techniques for continuous and discrete variables are discussed below. In probabilistic terms, the integrals we wish to approximate correespond to the expected value of some observable, $\mathcal{O} : \mathcal{S} \to \mathbb{R}$. Here we assume some implicit probability measure $m$ on $\mathcal{S}$, the latter called the <strong>state space</strong>. Formally, the expected value $\mathbb{E}_m \mathcal{O}$ corresponds to the integral
$$
\mathbb{E}_m \mathcal{O} = \int_{ \mathcal{S} } \mathcal{O}(s) \,  m( \textrm{d} s )
$$
When $m$ is understood, we write this expectation either as $\mathbb{E} \mathcal{O}$, or as $\langle \mathcal{O} \rangle$, the latter notation more common in physics.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We want to simulate most of the objects discussed throughout the notes, so we lose no generality in assuming that $\mathcal{S}$ is finite. $\mathcal{S}$ will be treated as a continuous object when it is more natural or convenient notationally. In the setting where $\mathcal{S}$ is finite, probability measures $m$ on $\mathcal{S}$ correspond to non-negative vectors $(m_i)_{i=1}^{\# \mathcal{S}}$ of length $\#\mathcal{S}$ whose entries sum to one. This vector is identical to the probability mass function (pmf) of $m$. We distinguish between two approaches for sampling from $m$: <strong>direct sampling</strong> and <strong>Markov chain sampling</strong>. We postpone giving the definition of a Markov chain.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="direct-sampling">
<a class="anchor" href="#direct-sampling" aria-hidden="true"><span class="octicon octicon-link"></span></a>direct sampling<a class="anchor-link" href="#direct-sampling"> </a>
</h2>
<p><em>(Krauth 1.1.1)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Krauth explains the concept of direct sampling through a game played with pebbles. The playing field is a large circle is inscribed into a large square, both drawn in the sand. In direct sampling, one has 'access' to the measure $m$ on $\mathcal{S}$. This means we can draw a collection of i.i.d. random variables $(X_i)_{i=1}^\infty$ taking values in $\mathcal{S}$, each with pmf corresponding to $m$. In the context of the game, we will assume we can directly sample from $m$, which here denotes the uniform measure on the square 
$$
\mathcal{S} \equiv \textsf{square} = [-1,1]^2   \,,
$$ 
a 'birds-eye' view of the playing field. The observable considered in the game is related to the game's objective: to compute an approximation of the number $\pi$. The observable $\mathcal{O} : \mathcal{S} \to \mathbb{R}$ is the indicator function of the unit disc, 
$\textsf{disc} = \{ s = (x,y) \in \textsf{square} : x^2 + y^2 \leq 1 \}$
$$
\mathcal{O} \equiv \mathbf{1}_{ \textsf{disc}} =
\begin{cases}
1 &amp; \quad s \in \textsf{disc} \\
0 &amp; \quad \textrm{otherwise}
\end{cases} 
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ A player throws pebbles at the square, successively. Through the direct sampling, these land uniformly at random. The sampling is performed independently across draws from $m$. In particular, no pebble throw ever misses the square. Let $S_1, \dots, S_N$ denote the collection of locations sampled from $\textsf{square}$ through the above procedure: each $S_i$ is a random ordered pair $S_i = (x_i, y_i) \in \textsf{square}$, where the collection of all coordinates, across all pairs, is mutually independent, with eeach coordinate a $\textrm{Unif}([-1,1])$ random variable.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ To describe how the samples $S_i$ are used to approximate the value of $\pi$, we introduce the <strong>empirical measure</strong> $m_N^{\textrm{direct}}$, a random probability measure on $\mathcal{S}$, defined so as to encode the locations $S_1, \dots, S_N$: 
$$
m_N^{\textrm{direct}} := \frac{1}{N} \sum_{i=1}^N \delta_{S_i},
$$
where in general $\delta_S$ denotes the delta mass at some random point $S$.  Measures are in a sense dual to sets, and the <strong>delta mass</strong> $\delta_X$ is a measure acting on sets in the following way: given measurable $B \subset \textsf{square}$, we have
$$
\delta_S = 
\begin{cases}
1 &amp; \quad \textrm{ if } S \in B, \\
0 &amp; \quad \textrm{ otherwise. }
\end{cases}
$$
The empirical measure $m_N^{\textrm{direct}}$, by definition, acts on sets $B \subset \mathcal{S}$ by reporting the fraction of the direct samples $S_i$ landing in $B$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ There is a sense in which the measures $m_N^{\textrm{direct}}$ 'converge' to $m$, and the game (or simulation) computes $\pi$ in a way which leverages this. Let us enumerate the states of $\mathcal{S} = \{s_1, \dots, s_M \}$. In practice, the size of $M$ will be determined by the resolution of the floating points used in sampling. In accordance with the observable $\mathcal{O}$, the set we choose for $B$ is $\textsf{disc}$. This is because
$$
m_N^{\textrm{direct}}( \textsf{disc} ) = \frac{1}{N} \sum_{i=1}^N \delta_{S_i}( \textsf{disc} ) \equiv \frac{1}{N} \sum_{i=1}^M \mathcal{O}(S_i)
$$
The sense in which $m_N^{\textrm{direct}}$ converges to $m$ implies, in particular, that the sequence of numbers $m_N^{\textrm{direct}}(\textsf{disc})$ converges to $m( \textsf{disc} )$ as $N \to \infty$. This convergence can also be seen as a consequence of a law of large numbers. The output of the first algorithm below is 
$$
4 \cdot m_N^{\textrm{direct}}(\textsf{disc}) \approx 4 \cdot m( \textsf{disc}) \equiv 4 \cdot \frac{ \pi}{4} 
$$
Thus we are approximating $\pi$ by approximating $\pi/4$, which is the probability that a pebble sampled from $m$ lands in $\textsf{disc}$. Python imports:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">default_rng</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">default_rng</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The next function embodies the 'direct' sampling we supposedly have access to, with the independence assumptions described above.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Unif">
<a class="anchor" href="#Unif" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unif<a class="anchor-link" href="#Unif"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># uniform r.v. over interval [0,1]</span>
<span class="k">def</span> <span class="nf">Unif</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Algorithm 1.1 is translated from pseudocode (as it is presented in Krauth) to Python.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Algorithm.-(-direct_pi-)">
<a class="anchor" href="#Algorithm.-(-direct_pi-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Algorithm.</strong> ( direct_pi )<a class="anchor-link" href="#Algorithm.-(-direct_pi-)"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">direct_pi</span><span class="p">(</span><span class="n">N</span> <span class="o">=</span> <span class="mi">4000</span><span class="p">):</span>

    <span class="n">N_hits</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="sd">"""</span>
<span class="sd">    the for loop is basically about computing the sum in</span>
<span class="sd">    \mu_N(disc), stored in N_hits</span>
<span class="sd">    """</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>

        <span class="c1"># initialize Unif([-1,1]) r.v.'s</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Unif</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Unif</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">rad_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">rad_sq</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>

            <span class="n">N_hits</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="sd">"""</span>
<span class="sd">    \mu_N(disc) is then computed by dividing by N</span>
<span class="sd">    """</span>
    <span class="n">ratio</span> <span class="o">=</span> <span class="n">N_hits</span> <span class="o">/</span> <span class="n">N</span>

    <span class="k">return</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">ratio</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Running the above:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">direct_pi</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3.103</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ In Krauth, Table 1.1 gives results of five runs of the above with <code>N = 4000</code>. We return to this table later to compare with Monte Carlo methods. He remarks that none of the results of this table have fallen in the error bounds known since Archimedes.</p>
<table>
<thead>
<tr>
<th>run</th>
<th><code>N_hits</code></th>
<th>estimate of $\pi$</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>3156</td>
<td>3.156</td>
</tr>
<tr>
<td>2</td>
<td>3150</td>
<td>3.150</td>
</tr>
<tr>
<td>3</td>
<td>3127</td>
<td>3.127</td>
</tr>
<tr>
<td>4</td>
<td>3171</td>
<td>3.171</td>
</tr>
<tr>
<td>5</td>
<td>3148</td>
<td>3.148</td>
</tr>
</tbody>
</table>
<p>Another remark of Krauth: <em>"The people adopt a sensible rule: they decide on the total number of throws, before they start the game."</em> (This is as in the above python code.) <em>"They understood that one must not stop a stochastic calculation simply because the current result appears accurate, nor should they continue to play because the answer they get isn't close enough to their idealized target."</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Markov-chain-sampling">
<a class="anchor" href="#Markov-chain-sampling" aria-hidden="true"><span class="octicon octicon-link"></span></a>Markov-chain sampling<a class="anchor-link" href="#Markov-chain-sampling"> </a>
</h2>
<p><em>( Krauth 1.1.2 )</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Cconsider a new game played on the same field, but with different rules. We again take a birds-eye view of the playing field, so our state space is again $\mathcal{S} = \textsf{square}$. The game starts with a person at the corner of the helipad, corresponding to coordinates $(1,1)$ in $\mathcal{S}$. The walker takes a step (or attempts to) by adding independent, $\textrm{Unif}([-\delta, \delta])$ random variables to each coordinate. Thus it is possible for a next step which takes the person outside the square. If this is the case, instead of taking the step, the walker does nothing. This step still 'counts' in the aggregation to be performed. Krauth describes this procedure in terms of the pebbles: the person takes another pebble from their bag and places it on top of the one pebble (or perhaps pebble pile) marking their current location. After an 'in-bounds' step is taken, the walker places a pebble at their current position. Each walker is equipped with a bag of infinitely many pebbles. These two cases describe the way the new game is played.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ In the present setting, the <strong>samples</strong> $X_1, \dots, X_N$ are not independent, but rather have the structure of a Markov chain, specifically a random walk with independent increments. Let us use $\xi_1, \dots, \xi_N$ denote these independent increments. In Krauth's description, each of these is a $\textrm{Unif}([-\delta, \delta])$ random variable. For reasons that Krauth discusses later, and we will comment on this, we instead assume that each $\xi_j$ is a discrete random variable uniformly distributed on the two-element set $\{ -\delta, \delta \}$. We have distinguished the starting point of the sampling at $X_0 = (1,1)$. Following the above description, one then has
$$
X_1 = 
\begin{cases}
X_0 + \xi_1\,, &amp; \quad \textrm{ if } X_0 + \xi_1 \in \textsf{square}\\
X_0 &amp; \quad \textrm{ otherwise }
\end{cases}
$$
and in general,
$$
X_j = 
\begin{cases}
X_{j-1} + \xi_j\,, &amp; \quad \textrm{ if } X_{j-1} + \xi_j \in \textsf{square}\\
X_{j-1} &amp; \quad \textrm{ otherwise }
\end{cases}
$$
for all $j = 1, \dots, N$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ For this new sequence of random $X_i$, we can define the analogous object to $m_N^{\textrm{direct}}$, 
$$
m_N^{\textrm{Markov}} := \frac{1}{N} \sum_{i=1}^N \delta_{X_i}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The algorithm below returns an approximation to $\pi$ via the same kind of ratio
$$
\pi \approx 4 \cdot m_N^{\textrm{Markov}}(\textsf{disc}) 
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ To comment on avoiding random initial conditions, specifically those which assign independent $\textrm{Unif}([-1,1])$ random variables to the two coordinates: we avoid this because the Markov chain methods stand out when no direct sampling method exists. It is for exactly this reason that we also avoid directly sampling from $\textrm{Unif}([-\delta, \delta])$ random variables: such objects are a linear transformation away from directly sampling from the $\textrm{Unif}([-1,1])$ distribution, perhaps at lower resolution. So, our Markov-chain sampling simulations start at the corner $(1,1)$ for concreteness. They can also be assumed to start from where a previous simulation left off. Following this convention throughout these notes, we usually focus on going from configuration $i$ to configuration $i+1$. This is the defining property of (discrete-time) Markov chains: the transition probabilities of the process depend only on the current position.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Algorithm.-(-markov-pi,-unmodified-)">
<a class="anchor" href="#Algorithm.-(-markov-pi,-unmodified-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Algorithm.</strong> ( markov-pi, unmodified )<a class="anchor-link" href="#Algorithm.-(-markov-pi,-unmodified-)"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">markov_pi</span><span class="p">(</span> <span class="n">delta</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">40000</span> <span class="p">):</span>

    <span class="c1"># initial conditions</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">N_hits</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">num_rej_moves</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># number of "rejected" moves</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>

        <span class="c1"># get coordinate increments</span>
        <span class="n">del_x_big</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Unif</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">del_y_big</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">Unif</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">del_x</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">del_x_big</span>

        <span class="n">del_y</span> <span class="o">=</span> <span class="n">delta</span> <span class="o">*</span> <span class="n">del_y_big</span>

        <span class="c1">#print(del_x, del_y)</span>

        <span class="c1"># potential new coordinates</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">del_x</span>

        <span class="n">y_new</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">del_y</span>

        <span class="c1"># to determine if step leads into disc</span>
        <span class="n">rad_sq_new</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x_new</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span> <span class="n">y_new</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span>

        <span class="c1"># ditto for square</span>
        <span class="n">x_in</span> <span class="o">=</span> <span class="n">x_new</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">x_new</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="n">y_in</span> <span class="o">=</span> <span class="n">y_new</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y_new</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="n">in_square</span> <span class="o">=</span> <span class="n">x_in</span> <span class="ow">and</span> <span class="n">y_in</span> 

        <span class="c1"># if move is accepted</span>
        <span class="k">if</span> <span class="n">in_square</span><span class="p">:</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">x_new</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">y_new</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">num_rej_moves</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># if in disc, +1 to number of hits</span>
        <span class="k">if</span> <span class="n">rad_sq_new</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>

            <span class="n">N_hits</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># we add in this output to </span>
    <span class="c1"># better understand how to pick </span>
    <span class="c1"># delta</span>
    <span class="nb">print</span><span class="p">(</span> <span class="s2">"fraction of successful moves: "</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span> <span class="n">num_rej_moves</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="p">)</span>

    <span class="k">return</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span> <span class="n">N_hits</span> <span class="o">/</span> <span class="n">N</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Running:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">markov_pi</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fraction of successful moves:  0.976
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3.104</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let's discuss the choice of 'throwing range', namely $\delta$. It is akin to (largest possible) step size for the walker. Roughly, if $\delta$ is too small, the acceptance rate may be high, but the claim is that the walk will not be able to explore enough to well-approximate the integral. Choosing $\delta$ too large means the walk will have a hard time making successful moves, also hindering exploration. Krauth: <em>"The time-honored rule of thumb consists in choosing $\delta$ neither too large, nor too small, so that the acceptance rate turns our to be on the order of $\frac{1}{2}$."</em> I didn't observe results agreeing with their rule of thumb. I found much more success with $\delta = 0.05$ versus their recommendation of $0.3$. I did however observe the approximation worsen as the step size was taken larger past $\delta = 1$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Algorithm.--(-markov-pi,-modified-)">
<a class="anchor" href="#Algorithm.--(-markov-pi,-modified-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Algorithm.</strong>  ( markov-pi, modified )<a class="anchor-link" href="#Algorithm.--(-markov-pi,-modified-)"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># in this modification, steps are no longer uniform  </span>

<span class="k">def</span> <span class="nf">markov_pi_modified</span><span class="p">(</span> <span class="n">delta</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">40000</span> <span class="p">):</span>

    <span class="c1"># initial conditions</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">N_hits</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">num_rej_moves</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># number of "rejected" moves</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        we use uniform random variables, out of convenience but not to</span>
<span class="sd">        determine coordinate steps directly with these. Instead, we </span>
<span class="sd">        extract a pair of fair coin tosses from two uniform random</span>
<span class="sd">        variables. We use these coin tosses only to determine the sign</span>
<span class="sd">        of the increment in each coordinate. </span>
<span class="sd">        """</span>

        <span class="c1"># generate indep uniforms</span>
        <span class="n">U_1</span> <span class="o">=</span> <span class="n">Unif</span><span class="p">()</span>

        <span class="n">U_2</span> <span class="o">=</span> <span class="n">Unif</span><span class="p">()</span>

        <span class="c1"># use these as coin tosses to determine </span>
        <span class="c1"># del_x...</span>

        <span class="k">if</span> <span class="n">U_1</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>
        
            <span class="n">del_x</span> <span class="o">=</span> <span class="n">delta</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">del_x</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta</span>

        <span class="k">if</span> <span class="n">U_2</span> <span class="o">&lt;=</span> <span class="mf">0.5</span><span class="p">:</span>

            <span class="n">del_y</span> <span class="o">=</span> <span class="n">delta</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">del_y</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta</span>

        <span class="c1"># potential new coordinates</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">del_x</span>

        <span class="n">y_new</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">del_y</span>

        <span class="c1"># to determine if step leads into disc</span>
        <span class="n">rad_sq_new</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x_new</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span> <span class="o">+</span> <span class="p">(</span> <span class="n">y_new</span> <span class="o">**</span> <span class="mi">2</span> <span class="p">)</span>

        <span class="c1"># ditto for square</span>
        <span class="n">x_in</span> <span class="o">=</span> <span class="n">x_new</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">x_new</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="n">y_in</span> <span class="o">=</span> <span class="n">y_new</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y_new</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="n">in_square</span> <span class="o">=</span> <span class="n">x_in</span> <span class="ow">and</span> <span class="n">y_in</span> 

        <span class="c1"># if move is accepted</span>
        <span class="k">if</span> <span class="n">in_square</span><span class="p">:</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">x_new</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">y_new</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="n">num_rej_moves</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># if in disc, +1 to number of hits</span>
        <span class="k">if</span> <span class="n">rad_sq_new</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>

            <span class="n">N_hits</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># we add in this output to </span>
    <span class="c1"># better understand how to pick </span>
    <span class="c1"># delta</span>
    <span class="nb">print</span><span class="p">(</span> <span class="s2">"fraction of successful moves: "</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span> <span class="n">num_rej_moves</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="p">)</span>

    <span class="k">return</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span> <span class="n">N_hits</span> <span class="o">/</span> <span class="n">N</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Running:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">markov_pi_modified</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>fraction of successful moves:  0.94765
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3.0008</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><strong>Q</strong> $\quad$ In both the Glauber and Metropolis dynamics for the evolution of the Ising model, the spin variable to be updated ( i.e. the vertex $v \in \mathbb{T}$ sampled ) is chosen uniformly, through <em>direct sampling</em>. What if this is instead done through Markov-chain sampling? Also, instead of rejecting the moves outside the box, we can play with periodic boundary conditions for the walks in both simulations.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="discussion">
<a class="anchor" href="#discussion" aria-hidden="true"><span class="octicon octicon-link"></span></a>discussion<a class="anchor-link" href="#discussion"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The Monte Carlo 'games' described above epitomize the two basic approaches to sampling from a probability measure $\mu$ on some space $\mathcal{S}$. Both approaches to the sampling evaluate an observable $\mathcal{O} : \mathcal{S} \to \mathbb{R}$. In our examples, $\mathcal{S} = \textsf{square}$, and the observable $\mathcal{O}$ is the indicator function of the disc within the square:
$$
\mathbf{1}_{\textsf{disc}}(s) = \begin{cases}
1 &amp; \quad s \in \textsf{disc} \\
0 &amp; \quad \textrm{otherwise}
\end{cases} \,, \quad \mathbf{1}_{\textsf{disc}} : \textsf{square} \to \mathbb{R} 
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In either sampling case, we can define $\mathcal{O}_i := \mathcal{O}(X_i)$, and note that one evaluates
$$
\frac{N_{\textrm{hits}}}{N} = \frac{1}{N} \sum_{i=1}^N \mathcal{O}_i \approx \mathbb{E}_m \mathcal{O},
$$
where $\mathbb{E}_m$ denotes the expected value taken with respect to the probability measure $m$, in this case (as before) uniform on $[-1,1]^2$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ In general, the pmf of $m$ doesn't appear in the approximation $\tfrac{1}{N} \sum_{i=1}^N \mathcal{O}_i$, Krauth: <em>"...rather than being evaluated, it is sampled. This is what defines the Monte Carlo method."</em> He goes on to point out that the multiple integrals also disappear: the expectation is formally an integral in two-variables, but we are approximating it by a path-integral indexed by time. <em>"This means that the Monte Carlo method allows the evaluation of high-dimensional integrals, such as appear in statistical physics and other domains, if we can only think of how to generate the samples."</em></p>
<p>$\quad$ Integration in two variables doesn't feel like a good example a 'high-dimensional' integral to compute. On the other hand, we are already know, through the motivating <a href="http://bit-player.org/2021/three-months-in-monte-carlo">blog post</a>, of a kind of Markov chain on a high-dimensional space, namely the Glauber dynamics for the Ising model on $\mathbb{T}$, the two-dimensional torus $( \mathbb{Z}\, /\, (n\cdot \mathbb{Z}) )^2$, with $n = 100$ for concreteness. All in all, it seems that one is approximating an integral in an arbitrary number of dimensions (number of spins in the case of Ising model) through what is essentially a path integral. The path integral is a sum of observables of the system, as the system evolves.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Krauth: <em>"Notwithstanding the randomness in the problem, direct sampling, in computation, plays a role similar to exact solutions in analyitcal work, and the two are closely related. In direct sampling, there is no throwing-range issue, no worrying about initial conditions, and there is a straightforward error analysis -- at least if $m$ and $\mathcal{O}$ are well behaved. Many successsful Monte Carlo algorithms contain exact sampling as a key ingredient. Markov-chain sampling, on the other hand, forces us to be much more careful with all aspects of our calculation. The critical issue here is the correlation time, during which the position of the walker retains a memory of the starting configuration. This time can become astronomical. In the usual applications, one is often satisfied with a handful of independent samples, obtained through week-long calculations, but it can require much throught and experience to ensure that even this modest goal is achieved."</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Markov-chains">
<a class="anchor" href="#Markov-chains" aria-hidden="true"><span class="octicon octicon-link"></span></a>Markov chains<a class="anchor-link" href="#Markov-chains"> </a>
</h2>
<p><em>(Menon 1.1, 1.2)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The perspective Menon starts his notes with: we model the world as a space of random signals. The world is filled with observers, which record part of these signals and then form inferences about the world. The process of inference is modeled with a Bayesian paradigm. We assume an observer has a stochastic model capable of generating signals similar to the true signal. These assumptions reduce inference to tuning the model parameters to obtain the best match between the generated and observed signals. For instance, if we know we are observing a simulation of the Ising model, inference reduces to estimating the temperature.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Menon's notes explore stochastic models of progressively increasing complexity, in tandem with numerical methods for optimization. The simplest class of stochastic models considered are Markov chains. Suppose we are given a finite set $\mathcal{S}$ called the <strong>state space</strong> of the Markov chain. This will sometimes (such as in text-modeling instances) be called the <strong>alphabet</strong>, in the context of language modeling. In the 'linguistic' interpretation of the Ising model dynamics, either Glauber or Metropolis dynamics are run to generate a sequence of spin configurations $s_1, \dots, s_N \in \mathcal{S}$. Each spin configuration (a binary image) is interpreted as a letter in the alphabet of some abstract language. An alphabet of astronomical size can seem useless, linguistically. The notion of a large alphabet, perhaps not astronomically so, seems to occur naturally when viewing language through a <em>coarse-grained</em> perspective. This is how we naturally read: not one letter at a time, but one word. The set of english words can then interpreted as an alphabet, one with around a million symbols. This touches upon the heirarchical structure of language (I'm not talking about Chomsky's heirarchy of languages, only the fact that our alphabet clusters into words, and those into sentences and so on).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-stochastic-process-)">
<a class="anchor" href="#Definition.-(-stochastic-process-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( stochastic process )<a class="anchor-link" href="#Definition.-(-stochastic-process-)"> </a>
</h3>
<p>$\quad$ A (discrete-time) <strong>stochastic process</strong> is a sequence of random variables.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We study a stochastic process $(X_t)_{t \in \mathbb{N}}$ taking values in the given finite set $\mathcal{S}$. Thus, the temporal (given by the index $t$ in the stochastic process) and the spatial (given by the state value in $\mathcal{S}$ of the process) aspects of this process are discrete.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-Markov-chain-)">
<a class="anchor" href="#Definition.-(-Markov-chain-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( Markov chain )<a class="anchor-link" href="#Definition.-(-Markov-chain-)"> </a>
</h3>
<p>$\quad$ The stochastic process $(X_t)_{t \in \mathbb{N}}$ is a <strong>Markov chain</strong> if for all $t,\,$ $\mathbb{P} ( X_{t +1} | X_1, \dots, X_t ) = \mathbb{P} (X_{t+1} | X_t )
$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ As the above definition indicates, the modeling assumption in Markov process theory is that the future of the process depends on the current state, but not the past. This is a probabilistic analogue of Newtonian determinism, encoded by the <em>forward equation</em> below. Stationary Markov chains are thus characterized by their <strong>transition matrix</strong> 
$$
Q(s, \tilde{s}) = \mathbb{P}( X_2 = \tilde{s} | X_1 = s )\,,
$$ 
with entries indexed by pairs of states $s, \tilde{s} \in \mathcal{S}$. Another interpretation of the Markov property is that the future and past are independent, conditional on the present. For simplicity, we usually assume Markov chains in consideration have the following structure:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-stationary-Markov-chain-)">
<a class="anchor" href="#Definition.-(-stationary-Markov-chain-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( stationary Markov chain )<a class="anchor-link" href="#Definition.-(-stationary-Markov-chain-)"> </a>
</h3>
<p>$\quad$ The Markov chain $(X_t)_{t \in \mathbb{N}}$ is <strong>stationary</strong> if for all $t$, $\mathbb{P}(X_{t+1} | X_t ) = \mathbb{P} (X_2 | X_1 )$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The most basic statistic associated to the Markov chain is the pmf of the random variable $X_t$. The mass assigned to state $s \in \mathcal{S}$ under this law is denoted
$$
m_t(s) := \mathbb{P}(X_t = s) \,,
$$
and one obtains the following recurrence relation using the so-called law of total probability, along with the definitions of $m_t$ and $Q$:
\begin{align}
m_{t+1}(\tilde{s}) &amp;= \mathbb{P} ( X_{t+1} = \tilde{s}) \\
&amp;= \sum_{s \in \mathcal{S}} \mathbb{P}( X_{t+1} = \tilde{s}, \, X_t = s ) \\
&amp;= \sum_{s \in \mathcal{S}} \mathbb{P} (X_{t+1} = \tilde{s} | X_t = s ) \mathbb{P}(X_t = s)  \\
&amp;= \sum_{s \in \mathcal{S}} Q(s,\tilde{s}) m_t(s)\,,
\end{align}
when we assume the chain is stationary. This calculation yields the <strong>forward equation</strong> 
$$
m_{t+1} = m_t Q , \quad t \in \mathbb{N}
$$
using the convention that the pmf $m_t$ of $X_t$ is regarded as a row vector.  The forward equation is linear and explicitly solvable when the chain is stationary. We proceed inductively to find
$$
m_t = m_1 Q^t , \quad t \in \mathbb{N} \,,
$$
and one of the central questions in Markov chain theory is to understand the behavior of $m_t$ as $t\to\infty$. This explains the importance of the eigenvalue spectrum of $Q$ to Markov chain theory: diagonalizing $Q$ is an efficient way to compute $Q^t$ for $t$ large, and the spectrum of $Q$ largely governs the long term behavior of the system.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="equilibrium-measures,-ergodicity,-random-walks">
<a class="anchor" href="#equilibrium-measures,-ergodicity,-random-walks" aria-hidden="true"><span class="octicon octicon-link"></span></a>equilibrium measures, ergodicity, random walks<a class="anchor-link" href="#equilibrium-measures,-ergodicity,-random-walks"> </a>
</h2>
<p><em>(Menon 1.2)</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-equilibrium-/-stationary-distribution-)">
<a class="anchor" href="#Definition.-(-equilibrium-/-stationary-distribution-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( equilibrium / stationary distribution )<a class="anchor-link" href="#Definition.-(-equilibrium-/-stationary-distribution-)"> </a>
</h3>
<p>$\quad$ Let $Q$ be the transition matrix of a stationary Markov chain $(X_t)_{t \in \mathbb{N}}$ with state space $\mathcal{S}$, and let $m$ be a probability measure on $\mathcal{S}$, whose pmf we also denote $m$. The measure $m$ is an <strong>equilibrium distribution</strong> or equivalently, a <strong>stationary distribution</strong> for $(X_t)_{t \in \mathbb{N}}$ if 
$$
m = m Q,
$$
and if $m$ satisfies the normalization conditions $m(s) \geq 0$ for all $s \in \mathcal{S}$ and $\sum_{s \in \mathcal{S}} m(s) =1$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The above definition is central to our simulation goals. For Markov chains with a unique stationary distribution $m$, the measures $m_t \equiv \mathbb{P}(X_t = \cdot )$ converge to $m$, in an appropriate sense, as $t \to \infty$. When we simulate a Markov chain, we are sampling from $m_t$, and the idea is to run the simulation long enough (taking $t$ large enough) so that $m_t \approx m$. This is how a Markov chain Monte Carlo (MCMC) simulation can be used to approximate sampling from $m$. The MCMC method then requires <em>finding</em> a stationary ergodic Markov chain in $\mathcal{S}$, whose stationary measure coincides with some $m$ we started with, and wish to sample from.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Krauth discussed the initial conditions of a Markov chain in the context of simulation: in the second pebble game, the person playing always had to start at a prescribed corner of the square. These are <em>deterministic</em> initial conditions. In practice, we assume simulations will start deterministically, or from where a previous simulation left off. In theory, it is useful to have a mathematical object associated to the <strong>initial conditions</strong> of a Markov chain: a probability measure on $\mathcal{S}$, denoted $m_0$. When initial conditions are deterministic, and start at some distinguished state $s_* \in \mathcal{S}$, the probability measure $m_0$ corresponds to the $\delta$-mass $\delta_{s_*}$. When $m_0$ is general, it models starting from where some simulation left off, whose information we have no (or only partial) access to.</p>
<p>$\quad$ The first equation in the above definition can be understood as describing the evolution of a Markov chain $(X_t)_{t \in \mathbb{N}}$ whose initial conditions are the stationary distribution $m$ associated to $(X_t)_{t \in \mathbb{N}}$. In this case $m_t = m$ for all $t$ if $m_1 = m$. That is, while the values of $X_t$ change with time (it's a stochastic process) its probability mass function does not. Menon: <em>"the equilibrium distribution of a Markov chain captures the intuitive idea of a dynamic equilibrium."</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Considering the task of computing $m$ given $Q$: $\,$ observe that $m$ is a left-eigenvector of $Q$ with eigenvalue $1$. Further, $1$ must always be an eigenvalue of $Q$ since it corresponds to the right-eigenvector $(1, \dots, 1)^T$. Thus, if we know how to solve for eigenvectors, we can determine $m$. Menon: <em>"what is interesting in practice is the converse: for large transition matrices, say when $\# \mathcal{S}$ is $10^6 \times 10^6$, it is more efficient to use Markov chains to approximate $m$, than to use naive linear algebra. This observation plays an important role in web crawlers and search engines."</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-ergodic-Markov-chain-)">
<a class="anchor" href="#Definition.-(-ergodic-Markov-chain-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( ergodic Markov chain )<a class="anchor-link" href="#Definition.-(-ergodic-Markov-chain-)"> </a>
</h3>
<p>$\quad$ A stationary Markov chain $X$ with state space $\mathcal{S}$ and transition matrix $Q$ is <strong>ergodic</strong> if it has a unique equilibrium distribution. A sufficient condition for ergodicity of $X$ is if for every pair $s, \tilde{s} \in \mathcal{S}$ there is a positive integer $j(s,\tilde{s})$ such that $Q^{j(s,\tilde{s})} &gt;0 $.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Many other conditions are known that ensure ergodicity. For example, if all terms of $Q$ are strictly positive, it is possible for any state to get to any other state, and this ensures that the Markov chain is ergodic. This assumption is too restrictive in practice, since we are mainly intersted in Markov chains making 'local' moves such as random walks in a large state space. This behavior is captured by the sufficient condition given in the above definition. Intuitively, it means that every state can visit every other state <em>given enough time</em>. We assume this property always holds.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Physicsts define the term ergodic ( describing Markov chain $(X_t)_{t\in \mathbb{N}}$ ) to mean the following.
$$
\lim_{T \to \infty} \sum_{t =1}^T \mathcal{O}(X_t) = \mathbb{E}_m\mathcal{O},
$$
where $m = m Q$ and $\mathcal{O}: \mathcal{S} \to \mathbb{R}$ is arbitrary. This formulation has the interpretation that a Markov chain is ergodic when the left-hand side, the <em>time-average</em>, is equal to the <em>spatial-average</em> (with respect to the equilibrium measure), which is the right hand side. Menon notes the following bottlenecks and simplifications:</p>
<ul>
<li>
<p>$\mathcal{S}$ may be very large. For example (in shuffling dynamics we soon describe), $\mathcal{S}$ may be the permutation group.</p>
</li>
<li>
<p>$Q$ may be a sparse matrix.</p>
</li>
<li>
<p>As discussed previously, we often don't need $m$ explicitly, we instead want to evaluate $\mathbb{E}_m \mathcal{O}$, where $\mathcal{O}: \mathcal{S} \to \mathbb{R}$ is some observable.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Example.-(-simple-random-walk-)">
<a class="anchor" href="#Example.-(-simple-random-walk-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Example.</strong> ( simple random walk )<a class="anchor-link" href="#Example.-(-simple-random-walk-)"> </a>
</h3>
<p>$\quad$ Let $G = (\textrm{V},\textrm{E})$ be a finite graph with vertex set $\textrm{V}$ and edge set $\textrm{E}$. Given $x,y \in \textrm{V}$, write $x \sim y$ if the edge $\{ x, y \}$ lies in $\textrm{E}$. Let $\textrm{deg}(x) \triangleq \sum_{x \sim y } 1$ be the degree of vertex $x$. A <strong>simple random walk</strong> on $G$ is a Markov chain with state space $\textrm{V}$ and transition matrix
$$
Q(x,y)=
\begin{cases}
\frac{1}{\textrm{deg}(x)}, &amp; \quad \text{ if } x \sim y \\
0 &amp; \quad \text{ otherwise. }
\end{cases}
$$
We leave the initial conditions ambiguous in this definition.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Example.-(-random-walks-in-the-permutation-group-)">
<a class="anchor" href="#Example.-(-random-walks-in-the-permutation-group-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Example.</strong> ( random walks in the permutation group )<a class="anchor-link" href="#Example.-(-random-walks-in-the-permutation-group-)"> </a>
</h3>
<p>$\quad$ Let $\mathfrak{S}_n$ denote the symmetric group on $n$ symbols, the collection of permutations on the set 
$$
[n] := \{ \, 1, \dots, n \, \},
$$ A permutation on $[n]$ is a bijective function from $[n]$ to itself, and the group structure is given by function composition. Below we describe two <em>distinct</em> Markovian dynamics on $\mathfrak{S}_n$ with the same stationary measure. These dynamics arise from putting distinct graph structures (writing $\sim'$ and $\sim''$ in this example) on a set of vertices indexed by $\mathfrak{S}_n$, and considering the associated simple random walk.</p>
<ol>
<li>
<p>We declare permutations $\sigma$ and $\tau$ adjacent and write $\sigma \sim' \tau$ if $\sigma$ and $\tau$ are related by a transposition of adjacent elements. The $'$-degree of each permutation in this graph is $n-1$.</p>
</li>
<li>
<p>We declare permutations $\sigma$ and $\tau$ adjacent and write $\sigma \sim'' \tau$ if $\sigma$ and $\tau$ are related by a transposition, not necessarily of adjacent elements. The $''$-degree of each permutation in this graph is ${n \choose 2}$.</p>
</li>
</ol>
<p>These are examples of <em>distinct</em> ergodic random walks on the same state space, namely $\mathfrak{S}_n$, both of which have the uniform measure as their equilibrium measure. The simulation 'purpose' of both random walks is thus to sample from this uniform measure, and the distinctness of the two walks raises the question of whether one method does the sampling better. This is a well-studied question, when $n = 52$ these two walks describe simple procedures for shuffling a deck of cards.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Shannon's-model-of-text">
<a class="anchor" href="#Shannon's-model-of-text" aria-hidden="true"><span class="octicon octicon-link"></span></a>Shannon's model of text<a class="anchor-link" href="#Shannon's-model-of-text"> </a>
</h2>
<p><em>( Menon 1.3 )</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The main idea in Shannon's model (of text / written language) is that text is text is a stationary, ergodic stochastic process $(X_t)$ taking values in an alphabet
$$
\mathcal{A} \triangleq \{\, a, \,b,\, c,\, \dots\,,\, z,\, \_ \,\}.
$$
We use $\mathcal{A}$ for this specific alphabet for clarity in examples which follow. This model of language is easily augmented to include punctuation and case, but we ignore this in the first approximation. We are not assuming that this process is a Markov chain. As discussed, the alphabet is the state space $\mathcal{S}$ from previous sections. Stationarity is distinct from the Markov property $-$ neither property implies the other.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-stationary-stochastic-process-)">
<a class="anchor" href="#Definition.-(-stationary-stochastic-process-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( stationary stochastic process )<a class="anchor-link" href="#Definition.-(-stationary-stochastic-process-)"> </a>
</h3>
<p>$\quad$ A discrete time stochastic process $X \equiv (X_t)$ is <strong>stationary</strong> if all abitrarily large, but finite, marginal probabilities are invariant under arbitrary shifts in time. More precisely,
$$
\mathbb{P} (\, X_1 = s_1, \dots, X_n = s_n\,) 
= \mathbb{P} ( \,X_{1+k} = s_1, \dots, X_{n+k} = s_n \,)
$$
for all positive integers $k$ and $n$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Stationarity means that if we were to observe strings of length $n$, their statistics are not changed by shifting them forward in time by an integer $k$. For such processes, the notion of ergodicity again means that <em>time averages</em> are equal to <em>spatial averages</em>. From the perspective of observables $\mathcal{O} : \mathcal{S}^n \to \mathbb{R}$, which through the above definition requires have an arbitrarily large 'memory' $n$ of the process, one has
$$
\lim_{T \to \infty} \frac{1}{T} \sum_{t =0 }^{T-1} \mathcal{O}(X_{t+1}, \dots, X_{t+n}) =
\mathbb{E}  \mathcal{O}( X_1, \dots, X_n) 
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Any discussion above of language and heirarchy was probably motivated by Menon, who among other things says:  <em>"the above assumptions are introduced to conform to the idea that written text contains many heirarchical structures: letters are joined by phonetic rules to form words, words are linked by the rules of grammar into sentences, sentences are organized into paragraphs, and so on. Strange as it may seem at first sight, these rules can be effectively modeled as a stochastic process. The use of stationary ergodic processes provides us with a definition flexible enough to include heirarchical structures (though these may be complex to write down), and simple enough to computationally test."</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ As discussed, written text is modeled by a stationary stochastic process $Y$, whose law is denoted
$$
\mathbb{P}_{\textrm{true}} .
$$
The subscript '$\textrm{true}$' indicates that we view $Y$ not as an approximation to language, but as a stream of 'correct' English text, generated in real-time. This idealization is vague, but the main point is to identify the written language $\mathcal{L}$, in this case English, with a concrete mathematical object: the stationary, stochastic process $Y$. The law $\mathbb{P}_{\textrm{true}}$ of this process is the analogue of $m$ in two previous contexts: the uniform measure on $\mathcal{S} = \textsf{square}$, and the uniform measure on $\mathcal{S} = \mathfrak{S}_{52}$. In either previous case, the purpose of the Markov chains involved was to approximately sample from $m$. Below, we discuss a family of Markov chains for approximately sampling from $m = \mathbb{P}_{\textrm{true}}$. The way in which this sampling happens here seems distinct from before, and is remarked on after we introducing the Markov chains approximating $\mathcal{L}$ below. Menon: "In practice, the probabilities relative to $\mathbb{P}_{\textrm{true}}$ below are approximated by mining a large corpus (e.g. the works of Shakespeare) to approximate $\mathbb{P}_{\textrm{true}}(a_1, \dots, a_n)$ for an arbitrary string $(a_1, \dots, a_n) \in \mathcal{A}^n$."</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Example.-(-digram-model-)">
<a class="anchor" href="#Example.-(-digram-model-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Example.</strong> ( digram model )<a class="anchor-link" href="#Example.-(-digram-model-)"> </a>
</h3>
<p><em>( or 2-gram model )</em></p>
<p>$\quad$ This is a Markov chain with state space $\mathcal{A} = \{ \, a,\, b, \, c, \, \dots \, , \,z, \, \_ \}$. 
$$
Q^{(2)}(x,y) = \mathbb{P}_{\textrm{true}} (\,X_2 = y | X_1 = x\,),
$$
which is to say, we form the character-to-character transition probabilities of a Markov process using the marginals of the full stationary process being approximated.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We can get better approximations by allowing the Markov chain above to retain more of its history by augmenting the state space to $\mathcal{A}^n$ for some $ n \geq 2$. When $n=2$, we obtain the so-called trigram model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Example.-(-trigram-model-)">
<a class="anchor" href="#Example.-(-trigram-model-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Example.</strong> ( trigram model )<a class="anchor-link" href="#Example.-(-trigram-model-)"> </a>
</h3>
<p><em>( or 3-gram model )</em></p>
<p>$\quad$ This is a Markov chain with state space $\mathcal{A}^2$, which we style as
$$
\{ aa, \,ab,\,, \dots, az, \dots, \_a, \, \dots, \, \_\,\_ \} 
$$
Let $x = a_1a_2$ and $y = b_1b_2$. In order to form a text of three letters from $x$ and $y$, we must ensure that $x$ and $y$ agree on their overlap, that is when $a_2 = b_1$, so that $x$ and $y$ combine to give us the string $a_1a_2b_2$. With this restriction on $x$ and $y$, we obtain the associated transition matrix
$$
Q^{(3)} (x,y) 
= \frac{\mathbb{P}_{\textrm{true}} ( a_1 a_2 b_2 ) }{
\mathbb{P}_{\textrm{true}}(a_1 a_2) }
$$
and $Q(x,y) =0$ when $a_2 \neq b_1$.</p>
<blockquote>
<p>Because of the compatability requirement of $a_2 = b_1$, the above Markov chain can still be viewed as a stochastic process taking values in $\mathcal{A}$, it is just no longer a Markov chain from this perspective. This is the sense, however, in which this model is approximating $\mathbb{P}_{\textrm{true}}$.</p>
</blockquote>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Example.-(-$(n+1$)-gram-model-)">
<a class="anchor" href="#Example.-(-%24(n+1%24)-gram-model-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Example.</strong> ( $(n+1$)-gram model )<a class="anchor-link" href="#Example.-(-%24(n+1%24)-gram-model-)"> </a>
</h3>
<p>$\quad$ A Markov chain with state space $\mathcal{A}^{n}$. A state $x$, say $x = (a_1, \dots, a_n)$ can be followed by a string $y = (b_1, \dots, b_n)$ only if $a_2 = b_1, a_3 = b_2, \dots, a_n = b_{n-1}$. This induces transition matrix
$$
Q^{(n+1)} (x,y) 
= \frac{\mathbb{P}_{\textrm{true}} ( a_1 a_2 \dots a_n b_n )}{\mathbb{P}_{\textrm{true}} (a_1 a_2 \dots a_n) }
$$
as above.</p>
<blockquote>
<p>Following the previous remark, for similar compatibility reasons, this Markov chain can also be interpreted as a stationary stochastic process taking values in $\mathcal{A}$. As before, this is the sense in which the above process approximates $\mathbb{P}_{\textrm{true}}$.</p>
<hr>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Menon: <em>"Shannon proved that as $n \to \infty$, the law of text generated by the above Markov approximations converges to the law of the true language. Note however that a good proof may not correspond to a good algorithm. For example, as $n$ increases, the size of the state space ( of the approximating Markov process ) grows exponentially. Thus the dimensions of the transition matrix are $\#\mathcal{A}^{2n}$, and worse yet, the size of the training data ( to determine $Q^{(n+1)}$ by mining ) also expands exponentially. This follows the rules of everyday language. Once $n$ gets large enough, say $5$ or $6$ in practice, it is much more efficient to make our fundamental unit words, rather than letters, since the number of true words of length $5$ is much lower than the $26^5$ combinations that are possible. This reflects the true nature of the space $\</em>$ character. In effect, we are still using the digram model, though we have switched to a new 'alphabet' whose fundamental units are words."_</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="information-theory">
<a class="anchor" href="#information-theory" aria-hidden="true"><span class="octicon octicon-link"></span></a>information theory<a class="anchor-link" href="#information-theory"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>references</em></p>
<ul>
<li>
<p><a href="https://mfe.baruch.cuny.edu/maticivan/">Ivan Matic</a>, <em>Information Theory and Sanov's Theorem</em> (<a href="https://the-ninth-wave.github.io/matic.pdf">his notes</a> from July 21, 2018)</p>
</li>
<li>
<p>Thomas Cover, <em>Elements of information theory, Ch. 2</em></p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Before going further, let us return to the object $\mathbb{P}_{\textrm{true}}$, playing the role of $m$ in previous examples. When recalling previous examples, we identified $m$ as the uniform measure on $\mathcal{S}$, in either case. To be formal, $m = \mathbb{P}_{\textsf{true}}$ is a probability measure on $\mathcal{S} \equiv \mathcal{A}^\infty$, where
$$
\mathcal{A}^\infty := \{ a \equiv (a_j)_{j=1}^\infty : a_j \in \mathcal{A} \textrm{ for all } j \}\,,
$$
the space of infinite sequences of elements of $\mathcal{A}$. Any discrete-time $\mathcal{A}$-valued stochastic process, given some initial conditions which we ignore, induces a probability measure on $\mathcal{A}^\infty$. This latter space has the interpretation of a 'path-space', as it is meant to contain all possible trajectories of the process.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The digram model naturally gives rise to a Markov chain with state space $\mathcal{A}$. Let us say that it induces measure $\mathbb{P}_{(2)}$ on $\mathcal{A}^\infty$. The trigram model is defined as a Markov chain with state space $\mathcal{A}^2$, but following the above remark, it can also be interpreted as a stationary stochastic process taking values in $\mathcal{A}$, inducing a measure $\mathbb{P}_{(3)}$ on the path-space $\mathcal{A}^\infty$. In general, the $(n+1)$-gram model induces measure $\mathbb{P}_{(n+1)}$ on $\mathcal{A}^\infty$. Our interpretation of what Menon says at the beginning of the most recent quote, is <em>"Shannon proved that..."</em> $\mathbb{P}_{(n+1)}$ converges to $\mathbb{P}_{\textrm{true}}$, in an appropriate sense.</p>
<blockquote>
<p>The approximation of $\mathbb{P}_{\textrm{true}}$ by $\mathbb{P}_{(n+1)}$ does <em>not at all</em> seeem to be an approximation of the same nature was is described in Krauth. By this I mean that $\mathcal{A}$-valued Markov chains do not play the same role in each case. In earlier cases, they served as a way to approximately sample from a probability measure on $\mathcal{A}$. In the present context, these objects induce a probability measure on the <em>path-space</em> $\mathcal{A}^\infty$, towards approximating $\mathbb{P}_{\textrm{true}}$, the probability measure on $\mathcal{A}^\infty$ encoding the '$\textrm{true}$' language.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Matic's add to the above discussion, as well as to Menon's upcoming discussion of entropy. Menon: <em>"the entropy of a random variable describes its uncertainty. In particular, the notion of an optimal code tells us that entropy describes the optimal search procedure to determine the value of $X$ through a series of yes / no questions."</em> Matic's notes touch on this optimality, from the perspective of data compression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ To integrate Matic's perspective, he starts by imagining <em>"...we want to store some big quantity of data, such as a picture, a text document, or a book. We start with a collection of uncompressed data, and we identify the smallest building blocks of each datum as symbols. The set of all symbols is called the alphabet."</em> Matic also denotes this alphabet as $\mathcal{A}$.</p>
<blockquote>
<p>It feels worth remarking that languages like Chinese are pictoral, and that Chinese characters can be decomposed into 'brushstrokes'. A space character <code>_</code> perhaps corresponds to moving to the next character. This lends itself to the notion that pictoral data can be decomposed into symbols. For images in general, I think 'contours' become the analogue of brushstrokes. Perhaps an efficient way to use a space character <code>_</code> is as denoting the start of a new transparent canvas layer, sitting over the previously drawn layers (copying the functionality of applications like photoshop). My impression of $3$-dim spatial data (e.g. virtual environments for games) is that environment information is efficiently stored in surfaces, the higher-dimensional analogue (by one dimension) of contours.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>The above decomposition reminds me of something I heard about the clustering algorithm <a href="https://towardsdatascience.com/t-sne-clearly-explained-d84c537f53a">t-SNE</a>: when applid to MNIST, the number of clusters the algorithm found was more than the number of categories (labeled by digits $0 - 9$). Some digits corresponded to multiple clusters <em>because</em> of there being distinct ways to write this digit, with or without a horizontal slash in the case of $7$, for example. In a sense, the clustering works too well.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Uncompressed data is called a <strong>signal</strong>. Mathematically, we model signals as elements of $\mathcal{A}^M$. Ideally, the signal is sampled from the measure $\mathbb{P}_{\mathcal{L}}$ on $\mathcal{A}^\infty$ corresponding to abstract language $\mathcal{L}$ over alphabet $\mathcal{A}$. This measure corresponds to a stochastic process $(X_t)_{t \in \mathbb{N}}$, which we suppose is stationary. Because of the 'optimal encoding' perspective, it is important to be able to quantify the relationship between the lengths of a signal and its encoding. In particular, we assume some upper bound $M$ on the signal length to begin with, modeling signals as elements of $\mathcal{A}^M$ for some $M \in \mathbb{N}$. When referring to $\mathbb{P}_{\mathcal{L}}$ in this context, it is understood as the projection of this measure onto $\mathcal{A}^M$, corresponding to the 'truncated' process $(X_t)_{t = 1}^{M}$, which is a random signal.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Our analysis takes place within an even simpler setting versus the language models discussed. Suppose $\mathbb{P}_{\mathcal{L}}$ corresponds to an i.i.d. sequence of random variables $(X_t)_{t = 1}^M$, where each $X_t$ has the same distribution as some 'model' random variable $X$, corresponding to probability measure $m$ on $\mathcal{A}$. Because $\mathcal{A}$ is finite, so is the space of signals $\mathcal{A}^M$. A lossless data compression is an injective function on this signal space.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-lossless-data-compression-)">
<a class="anchor" href="#Definition.-(-lossless-data-compression-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( lossless data compression )<a class="anchor-link" href="#Definition.-(-lossless-data-compression-)"> </a>
</h3>
<p>$\quad$ A <strong>lossless data compression</strong> is an injective function
$$
f : \mathcal{A}^M \to \bigcup_{j=1}^N \{ 0 , 1 \} ^j
$$
for some $N \in \mathbb{N}$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Given some lossless data compression $f$, and for each signal $s \equiv (s_1, \dots, s_M) \in \mathcal{A}^M$, we let $\textsf{length}_f(s)$ denote the length of the signal encoding $f(s)$. Letting $\mathbb{E}$ denote expectation with respect to the 'model' random variable $X$, desirable propereties of the compression $f$ make
$$
\mathbb{E} \, \textsf{length}_f(X) 
$$
as small as possible. Heuristically, this means <strong>(1)</strong> identifying the signals in $\mathcal{A}^M$ which are <em>typical</em> and <em>atypical</em>, according to the sampling $(X_t)_{t=1}^M$, and then <strong>(2)</strong> using shorter binary sequences to encode typical signals, leaving longer binary sequences for atypical signals. This means the expectation is placing as little probablistic mass as possible on the longest encodings.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let us use $m$ to denote the probability measure on $\mathcal{A}$ induced by the random variable $X$, our template for the i.i.d. sequence. Enumerating $\mathcal{A}$ as $\{ a_1, \dots, a_n\}$, let us write $m_i$ for the number $m( \{ a_i \})$. We identify $m$ with the vector $(m_1, \dots, m_n)$, which is the probability mass function of $X$. It is $m$ that determines how 'typical' a given sequence is.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let $s \equiv (s_1, \dots, s_M) \in \mathcal{A}^M$. Write $\underline{X}$ to denote the random vector $(X_t)_{t=1}^M$. The mutual independence of the $X_t$ implies
$$
\begin{align}
\mathbb{P}( \, \underline{X} = s ) &amp;= \mathbb{P} (X_1 = s_1) \dots \mathbb{P}(X_M = s_M) \\
&amp;= 2^{ \sum_{t=1}^M \log_2\mathbb{P}(X_t = s_t)}\\
&amp;= 2^{ \sum_{i=1}^n n_i \log_2 m_i}
\end{align}
$$
where, in going from the second to third line, we have reindexed the sum over the alphabet, using that $m_i \equiv \mathbb{P}(X = a_i)$, and defining
$$
n_i := \# \{ \, t \in \{ 1, \dots, M \} : X_t = a_i \, \}.
$$
Thus, $n_i$ is the number of times symbol $a_i$ appears in the random signal $\underline{X}$. A typical message is one  in which the frequency of symbol $a_i$ is close to the corresponding probability $m_i$. Thus, for typical messages, we have $n_i \approx m_i M $, and the probability of such a message is approximately
$$
2^{ M \sum_{i=1}^n m_i \log m_i }
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-entropy-)">
<a class="anchor" href="#Definition.-(-entropy-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( entropy )<a class="anchor-link" href="#Definition.-(-entropy-)"> </a>
</h3>
<p>$\quad$ Let $m$ be a probability measure on finite state space $\mathcal{A}$ with $\# \mathcal{A} = n$, corresponding to probability mass function $(m_1, \dots, m_n)$. The <strong>entropy</strong> of $m$ is 
$$
\textsf{S}(m) := - \sum_{i=1}^n m_i \log_2 m_i
$$</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let $X$ be a random element of $\mathcal{S}$ corresponding to the probability measure $m$. Cover has the following remark: <em>"Note that entropy is a functional of the distribution of $X$. It does not depend on the actual values taken by the r.v. $X$, only on the probabilities."</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Note that $\textsf{S}(m) \geq 0$, and is $=0$ if and only if $m$ corresponds to a deterministic object, namely a $\delta$-mass at some symbol in the alphabet, using the convention $0 \log 0 = 0$. In the above setting, we are imagining the length $M$ of the signal is much larger than the size $n$ of the alphabet $\mathcal{A}$. This is so that the law of large numbers has a chance to kick in for each symbol. In this setting, typical messages appear with probability on the order of $2^{-M \textsf{S}(m)}$. When $m$ is non-trivial, the positivity of $\textsf{S}(m)$ implies that typical signals are <em>exponentially rare</em>, in the signal length $M$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ A consquence of the intrinsic high-dimensionality of $\underline{X}$ -- which corresponds to a probability measure on $\mathbb{R}^M$, with $M$ large -- is that signals with symbol frequencies <em>close</em> to the corresponding $m_i$ are very common. The next definition formalizes this.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-$\epsilon$-typical-signal-)">
<a class="anchor" href="#Definition.-(-%24%5Cepsilon%24-typical-signal-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( $\epsilon$-typical signal )<a class="anchor-link" href="#Definition.-(-%24%5Cepsilon%24-typical-signal-)"> </a>
</h3>
<p>$\quad$ For fixed $\epsilon &gt; 0$, we say $s \in \mathcal{A}^M$ is <strong>$\epsilon$-typical</strong> if
$$
\mathbb{P}( \, \underline{X} = s ) \in \left( 2^{-M(\textsf{S}(m) +\epsilon) }, \, 2^{-M(\textsf{S}(m) -\epsilon) } \right) \,,
$$
and the set of all $\epsilon$-typical signals is denoted $\mathcal{A}^M_\epsilon$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ As discussed, the goal is to efficiently compress signals $\underline{X}$ drawn from the measure $m$. The relevance of the above defininition to compression is:</p>
<ol>
<li>
<p>we first prove that $\underline{X}$ is $\epsilon$-typical with high probability</p>
</li>
<li>
<p>we will see that the set of typical signals is nonetheless small: the number of all possible signals is $\# \mathcal{A}^M \equiv n^M$, and there are only approximately $2^{M\textsf{S}(m)}$</p>
</li>
</ol>
<p>these facts combine to form a compression strategy: when we see a typical message, we begin its binary encoding (towards defining the lossless compression function $f$) with <code>0</code>, and we use $M \textsf{S}(m)$ bits to compress it. If the message is atypical, we begin its binary encoding with a <code>1</code>, and are more sloppy with how many bits we use to store. The formal statement of the first point is as follows.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Theorem.-(-Matic,-Theorem-1)">
<a class="anchor" href="#Theorem.-(-Matic,-Theorem-1)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Theorem.</strong> ( Matic, Theorem 1)<a class="anchor-link" href="#Theorem.-(-Matic,-Theorem-1)"> </a>
</h3>
<p>$\quad$ For each $\delta &gt; 0$, there is $M_0 \in \mathbb{N}$ such that for every $M \geq M_0$ there is a lossless data compression $f$ in which the average length of a message satisfies</p>
$$
\mathbb{E} \textsf{length}_f ( \,\underline{X} ) \leq M \textsf{S}(m) + \delta 
$$<hr>
<p><em>( we defer recording the proof )</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Matic: <em>"The algorithm constructed (in the above proof) creates a lossless compression. It is very effective when the raw data consists of independent components. The <code>png</code> format uses a better algorithm."</em> To discuss this algorithm, Matic introduces what he calls <em>types</em>. These objects were previously introduced as the frequencies $n_i$ above.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-the-type-of-a-signal-)">
<a class="anchor" href="#Definition.-(-the-type-of-a-signal-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( the type of a signal )<a class="anchor-link" href="#Definition.-(-the-type-of-a-signal-)"> </a>
</h3>
<p>$\quad$ Given a signal $s \equiv (s_t)_{t=1}^M \in \mathcal{A}^M$, the <strong>type</strong> of $s$ is the following probability measure on $\mathcal{A}$, constructed through the symbol frequencies of $s$: for $a \in \mathcal{A}$, 
$$
m_s( \{ a \} ) := \frac{1}{M} \sum_{t = 1}^M \mathbf{1}\{ s_t = a \}
$$</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ As a direct consequence of the above definition, two signals $s, \tilde{s} \in \mathcal{A}^M$ have the same type if and only if the coordinates of $\tilde{s}$ form a permutation of the coordinates of $s$. Let $\textsf{types}(\mathcal{A},M)$ denote the collection of all types induced by signals in $\mathcal{A}^M$. The map $\mathcal{A}^M \to \textsf{types}(\mathcal{A},M)$ is effectively a quotient map, and given a probability measure $m \in \textsf{types}( \mathcal{A}, M)$, we let $\textsf{signals}(m)$ denote the collection of signals whose type is $m$:
$$
\textsf{signals}(m) = \{ s \in \mathcal{A}^M : m_s \equiv m \}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Theorem.-(-Matic,-Theorem-2-)">
<a class="anchor" href="#Theorem.-(-Matic,-Theorem-2-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Theorem.</strong> ( Matic, Theorem 2 )<a class="anchor-link" href="#Theorem.-(-Matic,-Theorem-2-)"> </a>
</h3>
<p>Consider the set of types, namely $\textsf{types}( \mathcal{A}, M)$, with $\# \mathcal{A} = n$. One has</p>
<ol>
<li>
<p>$\#\, \textsf{types}( \mathcal{A},M) = {M + n -1 \choose M }$</p>
</li>
<li>
<p>$\# \, \textsf{types}( \mathcal{A}, M) \leq (M+1)^n$</p>
</li>
</ol>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let $\mu$ be a general probability measure on $\mathcal{A}$, corresponding to a random variable $Y$ and let $\underline{Y} \equiv (Y_t)_{t=1}^M$ be a sequence of i.i.d. random variables. Given fixed signal $s \in \mathcal{A}^M$, one has
\begin{align}
\mathbb{P}( \, \underline{Y} = s ) &amp;= \prod_{t=1}^M \mu( Y_t = s_t) \\
&amp;= 2^{ \sum_{t=1}^M \log_2 \mu( Y_t = s_t ) } \\
&amp;= 2^{ \sum_{a \in \mathcal{A} } \sum_{t =1}^M \mathbf{1} \{ X_t = a \} \log_2 \mu(Y_t = s_t)} \\
&amp;= 2^{ \sum_{a \in \mathcal{A} } \sum_{t =1}^M \mathbf{1} \{ X_t = a \} \log_2 \mu(Y_t = a)} \\ 
&amp;= 2^{ M \left[ \sum_{a \in \mathcal{A} } \left( \frac{1}{M} \sum_{t =1}^M \mathbf{1} \{ X_t = a \} \right) \log_2 \mu(Y_t = a) \right]} \\
&amp;= 2^{ M \left[m_s(a) \log_2 \mu(a) \right] }
\end{align}
The coefficient of $M$ in the exponent directly above can be written in terms of the relative entropy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-relative-entropy,-or-KL-divergence-)">
<a class="anchor" href="#Definition.-(-relative-entropy,-or-KL-divergence-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( relative entropy, or KL divergence )<a class="anchor-link" href="#Definition.-(-relative-entropy,-or-KL-divergence-)"> </a>
</h3>
<p>$\quad$ Let $m$ and $\mu$ be probability measures on some finite state space $\mathcal{S}$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>next in section</em></p>
<ul>
<li>relative entropy or KL divergence</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Gibbs-measures">
<a class="anchor" href="#Gibbs-measures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Gibbs measures<a class="anchor-link" href="#Gibbs-measures"> </a>
</h2>
<p><em>( Menon 1.4 )</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let us abstract away from the above settings, briefly. In particular, we forget everything about the state space $\mathcal{S}$, except that it is a finite set, let us say $\# \mathcal{S} = N$, and we enumerate the states of $\mathcal{S}$ as 
$$
s_1, \dots, s_N .
$$</p>
<blockquote>
<p>In the context of the Ising model simulation, $N = 2^{\# \mathbb{T}} \equiv 2^{100^2}$.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We suppose there is a distinguished function, $h : \mathcal{S} \to \mathbb{R}$, called the <strong>Hamiltonian</strong>. The Hamiltonian assigns to each state $s_i$ a corresponding <strong>energy</strong> $h(s_i)$. A Gibbs measure is a probability measure on $\mathcal{S}$, defined from $h$, designed to favor the sampling of low-energy states. In practice, one cares about how the collective behavior of the system changes as a function of the amount of thermal noise. It is traditional to parametrize the amount of thermal noise by an <strong>inverse temperature</strong> parameter $\beta \in [0, \infty ]$, which is the multiplicative inverse of the system's temperature. Thus $\beta = 0$ corresponds to an infinite temperature limit, and taking $\beta \to \infty$ corresponds to approaching absolute zero.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ To equip $\mathcal{S}$ with a $\beta$-dependent probability measure $m_\beta$, it suffices to specify a collection of functions of $\beta$
$$
p_1(\beta), \dots, p_N(\beta)
$$
corresponding to the probability mass function of $m_\beta$. These depend implicitly on $h$ and are defined as follows.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-Gibbs-measure-)">
<a class="anchor" href="#Definition.-(-Gibbs-measure-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( Gibbs measure )<a class="anchor-link" href="#Definition.-(-Gibbs-measure-)"> </a>
</h3>
<p>$\quad$ The <strong>Gibbs measure</strong> on $\mathcal{S}$ associated to Hamiltonian $h$ and inverse temperature $\beta &gt; 0$, is defined by</p>
$$
p_i( \beta) \propto \exp\left( - \beta h( s_i) \right)
$$<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Above, $\propto$ is denotes 'proportional to'. The implicit proportionality constant is non-ambiguous because of the constraint that these numbers sum to one. Being more explicit leads to an object of central importance called the partition function. The <strong>partition function</strong> is:
$$
Z(h,\beta) : = \sum_{ i = 1 }^N \exp ( - \beta h(s_i) )
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We can thus write the $p_i(\beta)$ in the above definition explicitly as
$$
p_i(\beta) = \frac{ \exp( - \beta h(s_i) ) }{ Z(h,\beta)} 
$$
It is useful to consider the endpoint cases $\beta = 0, \infty$. Without much loss of generality, we may assume the $s_i$ are ordered so that</p>
$$
h(s_1) &lt; h(s_2) &lt; \dots &lt; h(s_M) \,,
$$<p>and one can check that as $\beta \to 0$, namely in the "infinite-temperature" limit, the measure $m_\beta$ becomes uniform over $\mathcal{S}$. The intuition is that thermal noise completely washes away any bias coming from the Hamiltonian.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ On the other hand, in the zero-temperature limit $\beta \to \infty$, The measures $m_\beta$ tend towards concentrating all of their mass on the first state, which has lowest energy. In the limit, we do not even get a random object, provided that the above strict inequalities hold. A state with lowest energy is called a <strong>ground state</strong>. In the above setting, there is a unique ground state. In general, it's possible for the set of ground states to be larger than one, this can arise naturally from symmetries in the model. For instance, the Ising model always has two ground states, corresponding to all $(+1)$ spins and all $(-1)$ spins.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><em>next sections</em></p>
<ul>
<li>
<p>derivation of the Gibbs distribution (continuing Menon 1.4)</p>
</li>
<li>
<p>decoding scrambled text (Menon 1.5)</p>
</li>
<li>
<p>sampling from a Gibbs distribution (Menon 1.6)</p>
</li>
<li>
<p>the Metropolis algorithm (Menon 1.7, Krauth 1.1.4, 1.1.5)</p>
</li>
<li>
<p>Markov chains convergence to stationary distribution (Menon 1.8, 1.9)</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>The point of building up to this last section is that it lays the theoretical groundwork for how the MCMC method can be used to sample from a Gibbs distribution, abstracting the simulations run in the motivating <a href="http://bit-player.org/2021/three-months-in-monte-carlo">blog post</a>. What's next is to describe the Hamiltonian for the Ising model, from which the Gibbs measures and dynamics are automatically defined.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="simulation">
<a class="anchor" href="#simulation" aria-hidden="true"><span class="octicon octicon-link"></span></a>simulation<a class="anchor-link" href="#simulation"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Ising-model">
<a class="anchor" href="#Ising-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Ising model<a class="anchor-link" href="#Ising-model"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We are simulating the Ising model on the discrete, two-dimensional torus, of side-length 100:</p>
$$
\mathbb{T} := \left( \, \mathbb{Z} \, / \, (100 \cdot  \mathbb{Z}) \, \right)^2
$$<p>The torus is displayed as a large square grid, with the understanding of "periodic" boundary conditions. We use $\mathbb{T}$ interchangeably to denote the graph and its vertex set. We write $\textrm{E}(\mathbb{T})$ for the edge set of the graph. We write $v \sim w$ if vertices $v$ and $w$ are joined by an edge in $\textrm{E}(\mathbb{T})$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ In the Ising model, where the <strong>spin</strong> at a given vertex $v \in \mathbb{T}$ is a random variable, $s(v)$, taking values in $\{ \pm 1 \}$. A <strong>state</strong> of the Ising model is a possible realization of every $s(v)$, for $v \in \mathbb{T}$. The <strong>state space</strong> of the Ising model is</p>
$$
\begin{align}
\mathcal{S}_{\textrm{Ising}} &amp;= \{ \pm 1 \}^{ \mathbb{T} }\\ 
&amp;\equiv ( s(v) \in \{ \pm 1\} : v \in \mathbb{T} ).
\end{align}
$$<p>We do not define the random variables $s(v)$ individually -- instead, we equip the whole state space $\mathcal{S}$ with a family of Gibbs probability measures $( m_\beta : \beta \in [0, \infty] )$. These are completely determined by the Ising Hamiltonian.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Definition.-(-Ising-Hamiltonian-)">
<a class="anchor" href="#Definition.-(-Ising-Hamiltonian-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Definition.</strong> ( Ising Hamiltonian )<a class="anchor-link" href="#Definition.-(-Ising-Hamiltonian-)"> </a>
</h3>
<p>The <strong>Ising Hamiltonian</strong> (in its simplest form) is defined as</p>
$$
H_{\textrm{Ising}}(s) = - \sum_{ v \sim w } s(v) s(w) 
$$<p>for $s \equiv ( s(v) : v \in \mathbb{T} ) \in \mathcal{S}_{\textrm{Ising}}$.</p>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ The coefficient of $-1$ in each summand is sometimes written $-J$, for some <em>coupling constant</em> $J &gt; 0$. Here we are setting $J = 1$. The sum is indexed by the edges $e = \{v,w\} \in \textrm{E}(\mathbb{T})$ of $\mathbb{T}$. The negative sign is what makes this a model of <em>ferromagnetism</em>, in which neighboring spins are encouraged to align. To see why, note that for the associated Gibbs measure $m_{\,\textrm{Ising},\beta}$, and for $s \in \mathcal{S}_{\textrm{Ising}}$,</p>
$$
m_{\,\textrm{Ising},\beta}(s) \propto \exp \left( \beta \sum_{v \sim w } s(v) s(w) \right),
$$<p>where the negative sign in the Hamiltonian has cancelled with the negative sign in the definition of Gibbs measure. The double negative allows us to interpret the Hamiltonian as energy: it is physical for low-energy states to be preferred, a kind of nod to the principle of least action, and this is implemented by the exponential biasing the measure towards states whose energy is smallest (perhaps negative).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Regardless of $\beta$, the exponent in the above display is maximized at two configurations: the first in which $s(v) \equiv 1$ for each $v \in \mathbb{T}$, and the second in which $s(v) \equiv -1$ for each $v \in \mathbb{T}$. We call these states $s_+$ and $s_-$ respectively. That there are two ground states is due to the invariance of the Hamiltonian under 'spin-flip symmetry', i.e. the transformation taking each spin of a configuration to its negative.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Moreover, the system is always biased towards these two ground states when $\beta &gt; 0$, it's just that the degree of this bias is mediated by $\beta$. One can interpret this in a 'signal-to-noise' framework: the ground states are like signals, and $\beta$ controls the signal-to-noise ratio. The measures $m_\beta$ exhibit qualitatively different behavior for different ranges of $\beta$, effectively the concept of a phase transition. The Ising model is one of the simplest models that can exhibit this behavior. In particular, there is a <strong>critical inverse temperature</strong>, $\beta_c$, such that the Ising model exhibits distinct behavior for $\beta &gt; \beta_c$ and $\beta &lt; \beta_c$. This value implicitly depends on the fact that we are working with the Ising Hamiltonian on the specific graph $\mathbb{T}$. The case $\beta = \beta_c$ is special, and for now we only concern ourselves with the two regimes away from the critical point. _(If it's the case that simulation becomes more difficult near the critical point, how close to $\beta_c$ does one start to become seriously impeded by these difficulties?)_</p>
<table>
<thead>
<tr>
<th>..... $\beta$ range .....</th>
<th>temperature range</th>
<th>name of regime</th>
</tr>
</thead>
<tbody>
<tr>
<td>$[0, \beta_c)$</td>
<td>high-temperature</td>
<td>subcritical</td>
</tr>
<tr>
<td>$(\beta_c, \infty]$</td>
<td>low-temperature</td>
<td>supercritical</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="dynamics">
<a class="anchor" href="#dynamics" aria-hidden="true"><span class="octicon octicon-link"></span></a>dynamics<a class="anchor-link" href="#dynamics"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We revisit the description of the dynamics. We always need some initial conditions in the form of spin configuration in $\mathcal{S}_{\textrm{Ising}}$. A spin configuration $s \in \mathcal{S}_{\textrm{Ising}}$ is a function $\mathbb{T} \to \{ \pm 1\}$, and we choose to store this data in the computer as an $n \times n$ matrix. We also call this matrix $s$. The periodicity will be encoded in the Hamiltonian, as well as in the dynamics (the neighboring vertices of each site are defined according to this periodicity).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let us first suppose that updates to the configuration happen at discrete, integer times 
$$
1, 2, \dots, \mathfrak{t},
$$
at each such time a (possibly) new spin configuration is created in a way we describe later. This leads to the sequence of spin configurations 
$$
s_0, s_1, \dots, s_{\mathfrak{t}} \in \mathcal{S}_{\textrm{Ising}}.
$$
We avoid using $T$, because it already has the meaning of temperature, $T \equiv \beta^{-1}$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ In the case that it is later easier to think of updates as happening in continuous time (according to some collection of $\textrm{Exponential}$ clocks, for instance), we will write</p>
$$
t_1 &lt; t_2 &lt; \dots &lt; \mathfrak{t}
$$<p>for the sequence of update times. The final time $\mathfrak{t}$ may no longer be integer, but we can still use the same notation for the resulting sequence of spin configurations, in either case.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ From an earlier <a href="http://bit-player.org/2019/glaubers-dynamics">blog post</a> of Brian Hayes: <em>"There’s no evidence Glauber was thinking of his method as an algorithm suitable for computer implementation. The subject of simulation doesn’t come up in his 1963 paper, where his primary aim is to find analytic expressions for the distribution of up and down spins as a function of time. (He did this only for the one-dimensional model.) Nevertheless, Glauber dynamics offers an elegant approach to programming an interactive version of the Ising model. "</em> What Hayes calls 'Glauber' dynamics in the first post is actually 'Metropolis-Hastings' dynamics $-$ this was pointed out in the comments. Hayes wanted to understand the distinction between the two better, and the more recent blog post linked to at the top is the really nice result.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p><em>important simulation ingredients and notation</em></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>$\quad$ Write $\# \mathbb{T}$ for the number of sites ('pixels') in the torus $\mathbb{T}$.</p>
</li>
<li>
<p>$\quad$ For $v \in \mathbb{T}$, let $\textsf{neigh}(v)$ denote the neighbors of $v$ within $\mathbb{T}$. On a torus, every vertex has four neighbors. In contrast to the blog (which uses $\sigma$ to denote spin configurations, where we use $s$), we use $\sigma$ to denote the random field obtained from $s$ by, at each $v \in \mathbb{T}$, assigning the local aggregation
$$
\sigma(v) := \sum_{ w \, \in \, \textsf{neigh}(v) } s(w)\,,
$$
so that each $\sigma(v) \in \{ -4, -2, 0 , 2, 4\}$.</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<p>$\quad$ The dynamics rely on comparing the current energy of the lattice with the energy resulting from flipping the spin at $v$. We wish to write down the energy difference concisely. To this end, let $s^{[v]}$ denote the spin configuration obtained from $s$ via
$$
s^{[v]} = \begin{cases}
s(w) &amp; \quad \text{ if } w \neq v\\
-s(w) &amp; \quad \text{ if} w = v
\end{cases}
$$</p>
</li>
<li>
<p>$\quad$ Let $\delta_v H_{\textrm{Ising}}$ denote the change in energy in going from $H_{\textrm{Ising}}(s)$ to $H_{\textrm{Ising}}(s^{[v]})$:
$$
\delta_v H_{\textrm{Ising}}(s) = H_{\textrm{Ising}}(s^{[v]}) - H_{\textrm{Ising}}(s)  
$$</p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>_on computing $\delta_vH(s)$_</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ Let us see why we have the following equality, which is used in the pseudocode below. 
$$
\delta_vH_{\textrm{Ising}}(s) = 2 s(v) \sigma(v) 
$$
In taking the above difference, we can expand each of $H_{\textrm{Ising}}(s)$ and $H_{\textrm{Ising}}(s^{[v]})$. The sum in the Ising Hamiltonian is always indexed by the edges of the torus, $e \in \textrm{E}( \mathbb{T})$. We can partition this edge set according to $v$. Let $\textrm{E}_1(v)$ denote all edges having $v$ as an endpoint, and let $\textrm{E}_2(v)$ denote the complementary set in $\textrm{E}(\mathbb{T})$. Then,
$$
\begin{align}
H_{\textrm{Ising}}(s) &amp;=  - \sum_{ \, \{ u, w \} \,  \equiv \, e \, \in \, \textrm{E}(\mathbb{T}) } s(u)s(w) \\
&amp;= - \left( \sum_{ \, \{ u, w \} \,  \equiv \, e \, \in \, \textrm{E}_1(v) } s(u) s(w) \right) - \left( \sum_{ \, \{ u, w \} \,  \equiv \, e \, \in \, \textrm{E}_2(v) } s(u) s(w) \right) \\
&amp;= - s(v) \sigma(v) - \left( \sum_{ \, \{ u, w \} \,  \equiv \, e \, \in \, \textrm{E}_2(v) } s(u) s(w) \right)
\end{align}
$$
and when we compute the analogous quantity for $H_{\textrm{Ising}}(s^{[v]})$, the second term remains the same, while the first term has its sign flipped. Subtracting the "flipped Hamiltonian" from the original, the second terms cancel.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Algorithm.-(-Metropolis-Hastings-)">
<a class="anchor" href="#Algorithm.-(-Metropolis-Hastings-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Algorithm.</strong> ( Metropolis-Hastings )<a class="anchor-link" href="#Algorithm.-(-Metropolis-Hastings-)"> </a>
</h3>
<p>Repeat $\# \mathbb{T}$ times:</p>
<ol>
<li>
<p>Choose a site $v \in \mathbb{T}$ uniformly at random.</p>
</li>
<li>
<p>Compute $\sigma(v)$ by summing the spins of all vertices neighboring $v$.</p>
</li>
<li>
<p>Compute $\delta_v H_{\textrm{Ising}}(s) = 2 s(v) \sigma(v)$,</p>
</li>
<li>
<p>Spin flip protocol:</p>
<p>a. If $\delta_v H_{\textrm{Ising}}(s) &lt; 0$, set $s(v) = -s(v)$. This ensures that we visit the configuration $s^{[v]}$ whenever flipping the spin at $v$ lowers the energy of the spin configuration</p>
<p>b. If $\delta_v H_{\textrm{Ising}}(s) \geq 0$, flip the spin at $v$ with probability 
 $$
 \exp ( - \beta \delta_v H_{\textrm{Ising}}(s)  )
 $$</p>
</li>
</ol>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Algorithm.-(-Glauber-)">
<a class="anchor" href="#Algorithm.-(-Glauber-)" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Algorithm.</strong> ( Glauber )<a class="anchor-link" href="#Algorithm.-(-Glauber-)"> </a>
</h3>
<p>Repeat $\#\mathbb{T}$ times:</p>
<ol>
<li>
<p>Choose a site $v \in \mathbb{T}$ uniformly at random.</p>
</li>
<li>
<p>Compute $\sigma(v)$</p>
</li>
<li>
<p>Compute $\delta_v H_{\textrm{Ising}}(s) = 2s(v) \sigma(v)$</p>
</li>
<li>
<p>Flip the spin at $v$ with probability
$$
\frac{ \exp(\, - \beta \delta_v H_{\textrm{Ising}}(s) \,) }{1 + \exp( \, -\beta \delta_vH_{\textrm{Ising}}(s)\,)}
$$</p>
</li>
</ol>
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="implementation">
<a class="anchor" href="#implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>implementation<a class="anchor-link" href="#implementation"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>some resources</em></p>
<ul>
<li>
<p><a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html">https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html</a></p>
</li>
<li>
<p><a href="https://numpy.org/doc/stable/reference/random/index.html#random-quick-start">https://numpy.org/doc/stable/reference/random/index.html#random-quick-start</a></p>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>imports</em></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">default_rng</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">default_rng</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="coin_toss">
<a class="anchor" href="#coin_toss" aria-hidden="true"><span class="octicon octicon-link"></span></a>coin_toss<a class="anchor-link" href="#coin_toss"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">coin_toss</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">Unif</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">p</span><span class="p">:</span>

        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">else</span><span class="p">:</span>

        <span class="k">return</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="grid">
<a class="anchor" href="#grid" aria-hidden="true"><span class="octicon octicon-link"></span></a>grid<a class="anchor-link" href="#grid"> </a>
</h3>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">grid</span><span class="p">():</span>

    <span class="c1">##</span>
    <span class="c1">#   initialize</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">temperature</span><span class="p">,</span>
                 <span class="n">n</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> 
                 <span class="n">starting_spin_config</span> <span class="o">=</span> <span class="s1">'inf_temp'</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">n</span> 
        <span class="c1">#   ^ side-length of torus</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="mi">2</span> 
        <span class="c1">#   ^ a two-dimensional torus, by default</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">spins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> 
                              <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
        
        <span class="c1">##</span>
        <span class="c1"># initial conditions</span>
        <span class="c1">#</span>
        <span class="c1"># starting_spin_config =</span>
        <span class="c1">#     * 'inf_temp'</span>
        <span class="c1">#     * 'plus'</span>
        <span class="c1">#     * 'minus'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">starting</span> <span class="o">=</span> <span class="n">starting_spin_config</span>
        
        <span class="c1">##</span>
        <span class="c1">#   'inf_temp'</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">starting</span> <span class="o">==</span> <span class="s1">'inf_temp'</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>

                <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>

                    <span class="n">coin</span> <span class="o">=</span> <span class="n">coin_toss</span><span class="p">()</span>

                    <span class="k">if</span> <span class="n">coin</span><span class="p">:</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

                    <span class="k">else</span><span class="p">:</span>

                        <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="c1">##</span>
        <span class="c1">#    'plus'</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">starting</span> <span class="o">==</span> <span class="s1">'plus'</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>

                <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1">##</span>
        <span class="c1">#    'minus'</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">starting</span> <span class="o">==</span> <span class="s1">'minus'</span><span class="p">:</span>

            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>

                <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

        <span class="sd">"""</span>
<span class="sd">        later we implement some kind of loading</span>
<span class="sd">        from the end of a previous simulation</span>
<span class="sd">        """</span>

        <span class="c1"># regardless of the initial conditions,</span>
        <span class="c1"># we need a starting temperature, because</span>
        <span class="c1"># it governs each step of dynamics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>

        <span class="c1"># we need this to implement code related to</span>
        <span class="c1"># github author's "note on boltzmann weight"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_size</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>

        <span class="sd">"""</span>
<span class="sd">        on storing dynamics history.</span>
<span class="sd">        """</span>

        <span class="c1"># we will track how many microsteps</span>
        <span class="c1"># the dynamics take. Number of microsteps</span>
        <span class="c1"># initialized at 0. </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_time_step</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># this records initial conditions in history</span>

        <span class="n">first_key</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_time_step</span> <span class="p">)</span>

        <span class="n">first_spin_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">first_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">first_spin_list</span>

    <span class="c1">##</span>
    <span class="c1">#   given vertex (x,y) return a list of its </span>
    <span class="c1">#   four neighbors</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">neighbors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

        <span class="c1"># coordinates</span>
        <span class="n">y_north</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

        <span class="n">y_south</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

        <span class="n">x_east</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

        <span class="n">x_west</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span>

        <span class="c1"># tuples</span>
        <span class="n">north</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_north</span> <span class="p">)</span>

        <span class="n">south</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_south</span> <span class="p">)</span>

        <span class="n">east</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x_east</span><span class="p">,</span> <span class="n">y</span> <span class="p">)</span>

        <span class="n">west</span> <span class="o">=</span> <span class="p">(</span> <span class="n">x_west</span><span class="p">,</span> <span class="n">y</span> <span class="p">)</span>

        <span class="k">return</span> <span class="p">[</span> <span class="n">north</span><span class="p">,</span> <span class="n">south</span><span class="p">,</span> <span class="n">east</span><span class="p">,</span> <span class="n">west</span> <span class="p">]</span>

    <span class="c1">##</span>
    <span class="c1">#   using the neighbors method, we compute</span>
    <span class="c1">#   $\delta_v H(s)$ given v = (x,y)</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">delta_v_H</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

        <span class="c1"># s(v)</span>
        <span class="n">site_spin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span>

        <span class="c1"># get neighbors</span>
        <span class="n">nbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># get their spins</span>
        <span class="n">north_spin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">][</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>

        <span class="n">south_spin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">][</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>

        <span class="n">east_spin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">][</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>

        <span class="n">west_spin</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">][</span> <span class="n">nbs</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>

        <span class="c1"># compute sigma(v)</span>
        <span class="n">sigma_v</span> <span class="o">=</span> <span class="n">north_spin</span> <span class="o">+</span> <span class="n">south_spin</span> <span class="o">+</span> <span class="n">east_spin</span> <span class="o">+</span> <span class="n">west_spin</span>

        <span class="c1"># return</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">site_spin</span> <span class="o">*</span> <span class="n">sigma_v</span>

    <span class="sd">"""</span>

<span class="sd">    ( from the first github program, why we </span>
<span class="sd">      introduce self.max_size )</span>

<span class="sd">    NOTE ON BOLTZMANN WEIGHT: After calculating the weight as</span>
<span class="sd">    exp(dE/T), why the Math.min and </span>
<span class="sd">    MAX_VALUE? If dE has a large negative value,</span>
<span class="sd">    and T is very small, exp(dE/T) can cause </span>
<span class="sd">    floating-point overflow. For example, exp(8/0.01) </span>
<span class="sd">    is &gt; 10^347. JavaScript barfs on anything greater </span>
<span class="sd">    than 10^308.</span>

<span class="sd">    """</span>

    <span class="c1">##</span>
    <span class="c1">#   this function returns the boltzmann weight</span>
    <span class="c1">#   used to determine whether spin is flipped</span>
    <span class="c1">#   ( it is used in both types of dynamics )</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">boltzmann_weight</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="p">):</span>

        <span class="n">energy_change</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta_v_H</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="n">exponent</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="n">energy_change</span>

        <span class="n">raw_weight</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="n">exponent</span> <span class="p">)</span>

        <span class="c1"># to_return = np.min( raw_weight, self.max_size )</span>

        <span class="k">return</span> <span class="n">raw_weight</span> <span class="c1"># to_return</span>

    <span class="c1">##</span>
    <span class="c1">#   the next method handles the uniform selection</span>
    <span class="c1">#   of site v from the torus.</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">site_select</span><span class="p">(</span> <span class="bp">self</span> <span class="p">):</span>

        <span class="c1"># first define two random arrays</span>
        <span class="c1"># they are Gaussian random variables,</span>
        <span class="c1"># but this is going to be incidental. </span>

        <span class="c1"># to select a coordinate uniformly at random,</span>
        <span class="c1"># we pick the one with the largest value.</span>

        <span class="n">array_1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="p">)</span>

        <span class="n">array_2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="p">)</span>

        <span class="n">first_coord</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span> <span class="n">array_1</span> <span class="p">)</span>

        <span class="n">second_coord</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span> <span class="n">array_2</span> <span class="p">)</span>

        <span class="k">return</span> <span class="n">first_coord</span><span class="p">,</span> <span class="n">second_coord</span>

    <span class="c1">##</span>
    <span class="c1">#   we perform one step ( a "microstep" )</span>
    <span class="c1">#   of the metropolis dynamics. This will </span>
    <span class="c1">#   later be repeated N times to form a </span>
    <span class="c1">#   "macrostep"</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">metropolis_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># new time step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_time_step</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1">##</span>
        <span class="c1"># step 1: select site 𝑣 ∈ 𝕋 uniformly</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">site_select</span><span class="p">()</span>

        <span class="c1">##</span>
        <span class="c1"># step 2: compute 𝜎(𝑣) </span>
        <span class="c1"># step 3: compute 𝛿_𝑣 𝐻(𝑠) = 2 𝑠(𝑣) 𝜎(𝑣)</span>
        <span class="c1">#</span>
        <span class="c1"># ( both steps built into the function called )</span>
        <span class="n">delta_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta_v_H</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="c1">##</span>
        <span class="c1"># step 4: spin flip protocol</span>
        <span class="c1">#</span>
        <span class="c1">#</span>
        <span class="c1">#    a.   If 𝛿_𝑣 𝐻(𝑠) &lt; 0, set 𝑠(𝑣) = −𝑠(𝑣)</span>
        <span class="k">if</span> <span class="n">delta_H</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span>
        <span class="c1">#    </span>
        <span class="c1"># </span>
        <span class="c1">#    b.   If 𝛿_𝑣 𝐻(𝑠) ≥ 0, </span>
        <span class="c1">#   flip the spin at 𝑣 with probability</span>
        <span class="c1">#      p := exp( − 𝛽 𝛿_𝑣 𝐻(𝑠) )</span>
        <span class="k">else</span><span class="p">:</span>

            <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">boltzmann_weight</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

            <span class="n">boo</span> <span class="o">=</span> <span class="n">coin_toss</span><span class="p">(</span> <span class="n">p</span> <span class="p">)</span>

            <span class="k">if</span> <span class="n">boo</span><span class="p">:</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="k">pass</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">write_state</span><span class="p">()</span>
        

    <span class="c1">##</span>
    <span class="c1"># Now we do the analogous thing for Glauber,</span>
    <span class="c1"># the following is one "microstep" of Glauber </span>
    <span class="c1"># dynamics</span>
    <span class="c1">#</span>
    <span class="k">def</span> <span class="nf">glauber_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># new time step</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_time_step</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1">##</span>
        <span class="c1"># step 1: select site 𝑣 ∈ 𝕋 uniformly</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">site_select</span><span class="p">()</span>

        <span class="c1">##</span>
        <span class="c1"># step 2: compute 𝜎(𝑣)</span>
        <span class="c1"># step 3: compute 𝛿_𝑣 𝐻(𝑠) = 2 𝑠(𝑣) 𝜎(𝑣)</span>
        <span class="n">delta_H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">delta_v_H</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="c1">## </span>
        <span class="c1"># step 4: spin flip protocol:</span>
        <span class="c1">#</span>
        <span class="c1">#     flip the spin at 𝑣 with probability</span>
        <span class="c1">#</span>
        <span class="c1">#       exp( −𝛽 𝛿_𝑣 𝐻(𝑠) ) /</span>
        <span class="c1">#                         / ( 1 + exp( −𝛽 𝛿_𝑣 𝐻(𝑠) ) )</span>
        <span class="c1">#</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">boltzmann_weight</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

        <span class="n">p</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">/</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">weight</span> <span class="p">)</span>

        <span class="n">boo</span> <span class="o">=</span> <span class="n">coin_toss</span><span class="p">(</span> <span class="n">p</span> <span class="p">)</span>

        <span class="k">if</span> <span class="n">boo</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="k">pass</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">write_state</span><span class="p">()</span>


    <span class="sd">"""</span>
<span class="sd">    before introducing methods that run a macrostep</span>
<span class="sd">    of each type of dynamics, we first provide a method</span>
<span class="sd">    that stores the current state of the system.</span>

<span class="sd">    In examining how to do this, it makes sense to </span>
<span class="sd">    provide `grid` with another attribute: </span>
<span class="sd">    `current_time_step` .. these numbers will serve </span>
<span class="sd">    as keys for the dictionary that stores the</span>
<span class="sd">    history of the dynamics</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="nf">write_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="n">dict_key</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_time_step</span> <span class="p">)</span>

        <span class="n">spin_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spins</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">dict_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">spin_list</span>

    <span class="c1"># the above stores spin state to dict</span>
    <span class="c1"># we also need a method that writes</span>
    <span class="c1"># the dict to a file whose name is provided</span>
    <span class="c1"># we store as .json </span>

    <span class="k">def</span> <span class="nf">write_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fp</span><span class="p">):</span>
      <span class="sd">"""dump the results of the simulation stored in `self.history` as json</span>
<span class="sd">      to the output file path specfied by the parameter `fp`</span>
<span class="sd">      """</span>
      <span class="kn">import</span> <span class="nn">json</span>
      <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fp</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Wrote results of simulation as json to </span><span class="si">{</span><span class="n">fp</span><span class="si">}</span><span class="s1">.'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$\quad$ We run the simulation for 10 microsteps of Metropolis dynamics, to test.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">grid</span><span class="p">(</span> <span class="n">temperature</span> <span class="o">=</span> <span class="mi">100</span> <span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">g</span><span class="o">.</span><span class="n">metropolis_step</span><span class="p">()</span>

<span class="n">g</span><span class="o">.</span><span class="n">write_history</span><span class="p">(</span> <span class="n">fp</span> <span class="o">=</span> <span class="s2">"./test.json"</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Wrote results of simulation as json to ./test.json.
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="n">fil</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span> <span class="s2">"./test.json"</span><span class="p">,</span> <span class="s1">'r'</span> <span class="p">)</span>

<span class="n">history_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span> <span class="n">fil</span> <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span> <span class="nb">type</span><span class="p">(</span><span class="n">history_dict</span><span class="p">)</span> <span class="p">)</span>

<span class="sd">"""</span>
<span class="sd">for key, value in history_dict.items():</span>
<span class="sd">    print(f"\n\nKey: {key}")</span>
<span class="sd">    print(f"\nValue: {value}\n")</span>
<span class="sd">"""</span>

<span class="n">fil</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

    </details>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class 'dict'&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/stat-mech/jupyter/2021/12/16/simulation.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/stat-mech/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/stat-mech/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/stat-mech/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>...</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/stat-mech/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/stat-mech/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
